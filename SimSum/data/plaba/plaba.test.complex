Purpose: Osteoarthritis of the knee is a common disease, often associated with a Baker's cyst.  Besides osteoarthritis, also other joint pathologies of the knee can be causative for a Baker's cyst.  Radiotherapy is known to be an effective treatment for osteoarthritis, with an anti-inflammatory effect.  As the excessive production of synovia usually is associated with intraarticular inflammation, our hypothesis was that radiotherapy might positively influence the synovial production and reduce the volume of a Baker's cyst.  Materials and methods: We performed a prospective trial, including 20 knees receiving radiotherapy for knee arthritis.  Besides documentation of NRS (numeric rating scale), WOMAC (Western Ontario and McMaster Universities Osteoarthritis Index) score and Knee Society Score, the volume of the Baker's cyst was calculated for a short- (6 to 12 weeks) and long-term (9 to 12 months) follow-up.  Ultrasonic volumetry was performed using an ultrasound device with a high-resolution multifrequency linear probe (6-9 MHz).  Results: Low-dose radiotherapy improved NRS, WOMAC score and Knee Society Score significantly.  The mean volume of Baker's cyst decreased from 22.3 ml to 10.7 respectively 3.1 ml during follow-up.  A decrease in volume of more than 25% compared to the baseline could be achieved for 75% of the patients in the short-term and 79% of the patients in the long-term follow up.  Conclusion: Radiotherapy of knee osteoarthritis is an effective treatment that decreases the volume of a Baker's cyst.  Most patients respond to the treatment.  Whether radiotherapy is an effective treatment for Baker's cyst without associated osteoarthritis has to be further examined.
Purpose: Osteoarthritis of the knee is a common disease, often associated with a Baker's cyst.  Besides osteoarthritis, also other joint pathologies of the knee can be causative for a Baker's cyst.  Radiotherapy is known to be an effective treatment for osteoarthritis, with an anti-inflammatory effect.  As the excessive production of synovia usually is associated with intraarticular inflammation, our hypothesis was that radiotherapy might positively influence the synovial production and reduce the volume of a Baker's cyst.  Materials and methods: We performed a prospective trial, including 20 knees receiving radiotherapy for knee arthritis.  Besides documentation of NRS (numeric rating scale), WOMAC (Western Ontario and McMaster Universities Osteoarthritis Index) score and Knee Society Score, the volume of the Baker's cyst was calculated for a short- (6 to 12 weeks) and long-term (9 to 12 months) follow-up.  Ultrasonic volumetry was performed using an ultrasound device with a high-resolution multifrequency linear probe (6-9 MHz).  Results: Low-dose radiotherapy improved NRS, WOMAC score and Knee Society Score significantly.  The mean volume of Baker's cyst decreased from 22.3 ml to 10.7 respectively 3.1 ml during follow-up.  A decrease in volume of more than 25% compared to the baseline could be achieved for 75% of the patients in the short-term and 79% of the patients in the long-term follow up.  Conclusion: Radiotherapy of knee osteoarthritis is an effective treatment that decreases the volume of a Baker's cyst.  Most patients respond to the treatment.  Whether radiotherapy is an effective treatment for Baker's cyst without associated osteoarthritis has to be further examined.
Background: This study aimed to compare the arthroscopic internal drainage of popliteal cysts alone or in combination with cyst wall resection in terms of clinical outcomes.  Methods: Forty-two consecutive patients with symptomatic popliteal cysts received arthroscopic treatment.  Specifically, 20 of them received arthroscopic internal drainage (AI group) alone and 22 received arthroscopic internal drainage combined with cyst wall resection (AICR group) through double posteromedial portals.  Magnetic resonance imaging (MRI) was performed to identify recurrence of popliteal cysts.  The Lysholm score and Rauschning-Lindgren grade were used to assess the clinical outcomes.  The median of the follow-up period was 24 months (12-48 months). Results: The two groups (AI group and AICR group) were similar in age, gender, cyst diameter, associated joint disorder, preoperative Lysholm score, preoperative Rauschning-Lindgren grade and follow-up period (P > 0.05).  Relative to the AI group, the AICR group had a significantly prolonged operation time (P < 0.05) and a higher incidence of complications (P < 0.05).  In both groups, the Rauschning-Lindgren grade at the last follow-up significantly differed from the preoperative grade (P < 0.05) and the Lysholm knee score remarkably increased compared to the preoperative score (P < 0.05); however, there were no differences between the two groups at the last follow-up (P > 0.05).  According to the MRI results, the cyst disappeared in 11 (55%), shrank in size in 6 (30%) and existed in 3 (15%) patients in the AI group, and was absent in 18 (81.8%) and shrank in size in 4 (18.2%) patients in the AICR group, suggesting a significant difference between the two (P < 0.05). Conclusion: Additional resection of cyst wall can result in a lower recurrence rate of cysts but extend the operation time and increase the incidence of perioperative complications compared with arthroscopic internal drainage of popliteal cysts alone.
Background: This study aimed to compare the arthroscopic internal drainage of popliteal cysts alone or in combination with cyst wall resection in terms of clinical outcomes.  Methods: Forty-two consecutive patients with symptomatic popliteal cysts received arthroscopic treatment.  Specifically, 20 of them received arthroscopic internal drainage (AI group) alone and 22 received arthroscopic internal drainage combined with cyst wall resection (AICR group) through double posteromedial portals.  Magnetic resonance imaging (MRI) was performed to identify recurrence of popliteal cysts.  The Lysholm score and Rauschning-Lindgren grade were used to assess the clinical outcomes.  The median of the follow-up period was 24 months (12-48 months). Results: The two groups (AI group and AICR group) were similar in age, gender, cyst diameter, associated joint disorder, preoperative Lysholm score, preoperative Rauschning-Lindgren grade and follow-up period (P > 0.05).  Relative to the AI group, the AICR group had a significantly prolonged operation time (P < 0.05) and a higher incidence of complications (P < 0.05).  In both groups, the Rauschning-Lindgren grade at the last follow-up significantly differed from the preoperative grade (P < 0.05) and the Lysholm knee score remarkably increased compared to the preoperative score (P < 0.05); however, there were no differences between the two groups at the last follow-up (P > 0.05).  According to the MRI results, the cyst disappeared in 11 (55%), shrank in size in 6 (30%) and existed in 3 (15%) patients in the AI group, and was absent in 18 (81.8%) and shrank in size in 4 (18.2%) patients in the AICR group, suggesting a significant difference between the two (P < 0.05). Conclusion: Additional resection of cyst wall can result in a lower recurrence rate of cysts but extend the operation time and increase the incidence of perioperative complications compared with arthroscopic internal drainage of popliteal cysts alone.
Objective: To review the results of arthroscopic treatment of popliteal cysts in our centre and analyse outcomes including complications.   Patients: From July 2007 to July 2009, 11 patients with symptomatic popliteal cysts were treated arthroscopically.  All of them had preoperative magnetic resonance imaging to confirm the diagnosis, identify the valvular opening, and the associated intra-articular pathology.  We used the Rauschning and Lindgren criteria for evaluation.  Results: Intra-articular pathology like cartilage degeneration and meniscus tear were commonly associated with popliteal cysts.  All patients achieved symptomatic improvement after treatment and the recurrence rate was low.  No major complications were encountered.  We failed to identify (and correct) any valvular opening in one patient.  Conclusion: From our experience, we conclude that arthroscopic treatment of popliteal cyst with correction of the valvular opening and treatment of associated intra-articular pathology is effective and safe.
Objective: To review the results of arthroscopic treatment of popliteal cysts in our centre and analyse outcomes including complications.   Patients: From July 2007 to July 2009, 11 patients with symptomatic popliteal cysts were treated arthroscopically.  All of them had preoperative magnetic resonance imaging to confirm the diagnosis, identify the valvular opening, and the associated intra-articular pathology.  We used the Rauschning and Lindgren criteria for evaluation.  Results: Intra-articular pathology like cartilage degeneration and meniscus tear were commonly associated with popliteal cysts.  All patients achieved symptomatic improvement after treatment and the recurrence rate was low.  No major complications were encountered.  We failed to identify (and correct) any valvular opening in one patient.  Conclusion: From our experience, we conclude that arthroscopic treatment of popliteal cyst with correction of the valvular opening and treatment of associated intra-articular pathology is effective and safe.
Popliteal cyst is a common peri-knee cyst, also known as a Baker's cyst. With the current development of popliteal cysts, the pathogenesis is mainly due to increased pressure in the knee joint caused by various reasons, leading to a fluid-filled sac that can form behind the knee as a result of enlargement of the gastrocnemius-semimembranosus bursa. The current diagnostic methods include X-ray computed, ultrasound, and magnetic resonance. Among them, magnetic resonance imaging is considered the gold standard for the diagnosis of popliteal cysts. There are various treatments, including conservative treatment, traditional surgical resection and arthroscopic surgery. In recent years, the focus of the treatment of popliteal cysts has gradually shifted from the simple removal of cysts to arthroscopic treatment of intra-articular lesions and the treatment of joint-cyst communication, and achieved a good effect. However, there are still controversies about the most effective treatment, and the best surgery method is still uncertained. It is hoped that high quality prospective studies will be able to directly compare different surgery methods, so as to select the best treatment for popliteal cyst. This article reviews past literature research and describes in detail the epidemiology, pathological mechanism, clinical manifestations and signs, auxiliary examination, diagnosis and differential diagnosis and clinical treatment of popliteal cysts. Different diagnosis methods and treatment methods are compared and summarized to provide basis for clinical diagnosis and treatment.
Context: Popliteal synovial cysts, also known as Baker's cysts, are commonly found in association with intra-articular knee disorders, such as osteoarthritis and meniscus tears. Histologically, the cyst walls resemble synovial tissue with fibrosis evident, and there may be chronic nonspecific inflammation present. Osteocartilaginous loose bodies may also be found within the cyst, even if they are not seen in the knee joint. Baker's cysts can be a source of posterior knee pain that persists despite surgical treatment of the intra-articular lesion, and they are routinely discovered on magnetic resonance imaging scans of the symptomatic knee. Symptoms related to a popliteal cyst origin are infrequent and may be related to size. Conclusion: A capsular opening to the semimembranosus-medial head gastrocnemius bursa is a commonly found normal anatomic variant. It is thought that this can lead to the formation of a popliteal cyst in the presence of chronic knee effusions as a result of intra-articular pathology. Management of symptomatic popliteal cysts is conservative. The intra-articular pathology should be first addressed by arthroscopy. If surgical excision later becomes necessary, a limited posteromedial approach is often employed. Other treatments, such as arthroscopic debridement and closure of the valvular mechanism, are not well studied and cannot yet be recommended.
Purpose: The purpose of this study was to introduce a modified arthroscopic treatment technique for popliteal cyst and hypothesize that this modified technique would provide good clinical efficacy and low recurrence rate. Methods: From January 2013 to January 2017, 34 patients with symptomatic popliteal cysts were treated with our technique. A figure-of-four position and double posteromedial portals were used to achieve adequate enlargement of the posteromedial valvular opening between the cyst and the joint cavity and complete excision of the cyst wall. MRI was used to detect the recurrence of the popliteal cyst, and the Rauschning and Lindgren score was recorded to evaluate the clinical outcome. Results: All patients were followed up with a mean period of 14.8 months (range, 12 to 36 months). Associated intra-articular lesions were found and treated in all cases. Degenerative cartilage damage was the most common pathology, which affected 23 (67.6%) of the cases. The Rauschning and Lindgren score improved significantly after surgery, and no evidence of recurrence was found from MRI in any case. Conclusions: Our modified arthroscopic treatment technique, using a figure-of-four position and double posteromedial portals, is effective and safe for treating popliteal cyst.
Although popliteal cysts are most frequently identified in patients with osteoarthritis (OA), they may occur in patients with rheumatoid arthritis (RA), in which serious complicated cases such as cyst rupture can be developed. The objective of this study was to report four patients with RA (six knees) in combination with OA with a brief review of literature of previous similar published cases. This is a retrospective review of case records of patients with refractory and/or complicated popliteal cysts, who have successfully treated with arthroscopic intervention. We suggest that arthroscopic interventions such as radical debridement, synovectomy, biomechanical valve excision, and/or cystectomy should be considered in patients with refractory and complicated popliteal cysts associated with RA or RA in combination with OA.
Background: The purpose of this study was to evaluate the efficacy of arthroscopic knee cavity internal drainage and cyst cavity debridement operation of popliteal cyst in knee osteoarthritis patients. Methods: From August 2007 to March 2013, 58 knee osteoarthritis patients with popliteal cyst were treated with arthroscopic knee cavity internal drainage through posteromedial portal and popliteal cyst cavity debridement through superior posteromedial portal. In all patients, preoperative magnetic resonance imaging (MRI) was performed to detect combined intra-articular pathology and the communication between popliteal cyst and knee cavity. Clinical efficacy was evaluated through VAS score and Lysholm score. Results: All patients had neither recurrence of popliteal cyst nor complaints of pain, swelling, or functional impairment at average 24 months follow-up after surgery. Postoperatively, VAS score was decreased significantly and Lysholm score was raised significantly comparing preoperatively. Conclusion: Arthroscopic knee cavity internal drainage operation through posteromedial portal and popliteal cyst cavity debridement through superior posteromedial portal is an effective minimally invasive surgery method for the treatment of popliteal cyst without recurrence in knee osteoarthritis patients.
There is a lack of research comparing the clinical effects of arthroscopic treatment of popliteal cysts between the one posteromedial portal (OPP) technique and the two posteromedial portals (TPP) technique. The aim of this study was to evaluate and compare the clinical efficacy of arthroscopic treatment for popliteal cysts between the 2 techniques. Patients with symptomatic popliteal cysts after surgery were retrospectively invited to participate in this study. They received arthroscopy treatment via the OPP technique or the TPP technique. At the final follow-up, the Rauschning and Lindgren criteria and the Lysholm score were used for clinical evaluation. Moreover, magnetic resonance imaging was performed to detect the recurrence of cysts postoperatively. Finally, 53 patients with symptomatic popliteal cysts were included in this study, including 25 in the OPP group and 28 in the TPP group. The operation time of the TPP group was significantly longer than that of the OPP group (P < .001). In the OPP group, the cysts disappeared in 17 patients and reduced in size in 8 patients. In the TPP group, the cysts disappeared in 23 patients and reduced in size in 5 patients. According to the Rauschning and Lindgren classification, the recurrence rate was significantly lower in the TPP group (0%) than in the OPP group (4%) (P = .03). In addition, there was no significant difference in the Lysholm score between the OPP group and the TPP group (P = .77). TPP technique is more effective and superior than OPP technique for the treatment of popliteal cysts.
To reduce the damage to posteromedial knee capsule, we developed a direct extra-articular arthroscopic approach for excision of symptomatic popliteal cysts. This study aimed to demonstrate the surgical technique and present the 2-year follow-up results. Cystectomy is performed by extra-articular surgical approach through a high posteromedial portal. Twenty-one consecutive patients diagnosed of symptomatic popliteal cysts with failed initial conservative treatments were included. At a median follow-up of 29.4 months, all knees had improved clinical function assessed by Rauschning and Lindgren knee classification (p<0.001). The cysts were either disappeared (95.2%) or reduced in size (4.8%). Only one (4.8%) patient had recurrent cyst, which was solved after ultrasound-guided aspiration. This direct extra-articular arthroscopic technique could be a feasible alternative for treatment of symptomatic popliteal cysts.
Asthma is the most common chronic disease of childhood and, in the latter part of the 20th century, reached epidemic proportions. Asthma is generally believed to result from gene-environment interactions. There is consensus that a 'window of opportunity' exists during pregnancy and early in life when environmental factors may influence its development. We review multiple environmental, biologic and sociologic factors that may be important in the development of asthma. Meta-analyses of studies have demonstrated that multifaceted interventions are required in order to develop asthma prevention. Multifaceted allergen reduction studies have shown clinical benefits. Asthma represents a dysfunctional interaction with our genes and the environment to which they are exposed, especially in fetal and early infant life. The increasing prevalence of asthma also may be an indication of increased population risk for the development of other chronic non-communicable autoimmune diseases. This review will focus on the factors which may be important in the primary prevention of asthma. Better understanding of the complex gene-environment interactions involved in the development of asthma will provide insight into personalized interventions for asthma prevention.
Purpose of review: The prevalence of asthma is increasing in many parts of the world, particularly in developed countries. The present review focuses on recent literature regarding asthma prevention in childhood. Recent findings: Several environmental exposures in infancy or early childhood are associated with reduced prevalence of asthma, but the mechanisms leading to these associations remain unknown. Recent studies have demonstrated limited success in the prevention of asthma or asthma symptoms with the use of asthma medications, once the therapy is discontinued. Immunotherapy offers another strategy for asthma prevention, and groups treated with this intervention have demonstrated reduced atopy and asthma. Several multi-interventional trials have demonstrated a reduced asthma symptom burden but have not demonstrated significant differences in objective measures such as lung function or bronchial hyper-responsiveness between intervention groups. Summary: The most promising asthma prevention strategies to date have been those that use a multi-interventional approach employing both dietary and environmental manipulations. More research is needed to assess the long-term follow-up of multi-interventional trials and to evaluate novel intervention strategies in the primary or secondary prevention of asthma in childhood.
Purpose of review: The prevalence of asthma is increasing in many parts of the world, particularly in developed countries. The present review focuses on recent literature regarding asthma prevention in childhood. Recent findings: Several environmental exposures in infancy or early childhood are associated with reduced prevalence of asthma, but the mechanisms leading to these associations remain unknown. Recent studies have demonstrated limited success in the prevention of asthma or asthma symptoms with the use of asthma medications, once the therapy is discontinued. Immunotherapy offers another strategy for asthma prevention, and groups treated with this intervention have demonstrated reduced atopy and asthma. Several multi-interventional trials have demonstrated a reduced asthma symptom burden but have not demonstrated significant differences in objective measures such as lung function or bronchial hyper-responsiveness between intervention groups. Summary: The most promising asthma prevention strategies to date have been those that use a multi-interventional approach employing both dietary and environmental manipulations. More research is needed to assess the long-term follow-up of multi-interventional trials and to evaluate novel intervention strategies in the primary or secondary prevention of asthma in childhood.
Asthma, which typically begins in childhood and is the most common chronic disease of childhood, has reached epidemic proportions. Asthma is associated with gene-environment interactions, and there is consensus that a "window of opportunity" exists early in life when environmental factors may influence its development. This review considers biologic and sociologic factors in the development of allergy and asthma. Meta-analysis of studies demonstrates that monoallergen reduction does not impact asthma prevention. However, multifaceted allergen reduction studies have shown clinical benefit. We propose that allergic diseases, including asthma, represent a dysfunctional interaction with our environment and that the increasing prevalence of asthma and allergy herald increased population risk for the development of other inflammatory and autoimmune diseases. Better understanding of the complex factors for asthma and allergies may provide insight into many other chronic complex diseases.
Purpose of review: This article presents recent findings and perspectives on the relationship between early-life respiratory infections and asthma inception, and discusses emerging concepts on strategies that target these infectious agents for asthma prevention. Recent findings: Cumulative evidence supports the role of early-life viral infections, especially respiratory syncytial virus and human rhinovirus, as major antecedents of childhood asthma. These viruses may have different mechanistic roles in the pathogenesis of asthma. The airway microbiome and virus-bacteria interactions in early life have emerged as additional determinants of childhood asthma. Innovative strategies for the prevention of these early-life infections, or for attenuation of acute infection severity, are being investigated and may identify effective strategies for the primary and secondary prevention of childhood asthma. Summary: Early-life infections are major determinants of asthma development. The pathway from early-life infections to asthma is the result of complex interactions between the specific type of the virus, genetic, and environmental factors. Novel intervention strategies that target these infectious agents have been investigated in proof-of-concepts trials, and further study is necessary to determine their capacity for asthma prevention.
It has been 15 years since the first prevention of allergy (PAT) study was published, exploring the dream of the allergist: determining whether allergen-specific immunotherapy (AIT) can alter the natural course of disease and prevent the development of asthma in children with seasonal allergic rhino-conjunctivitis. Two hundred five children aged 6 to 14 years with grass and/or birch pollen allergy were randomized to receive either allergen-specific injection immunotherapy with aluminum-adsorbed native allergen extract subcutaneous immunotherapy for 3 years or to an open control group. Subjects had moderate-to-severe hay fever symptoms, but none of them reported asthma at the time of inclusion. Actively treated children had significantly fewer asthma symptoms after 3 years, as evaluated by clinical diagnosis (odds ratio, 2.52; P < .05). Methacholine bronchial provocation test results were significantly better in the active group. Thus a 3-year course of injection AIT in children with hay fever to grass, birch pollen, or both significantly reduced the risk of asthma.
It has been 15 years since the first prevention of allergy (PAT) study was published, exploring the dream of the allergist: determining whether allergen-specific immunotherapy (AIT) can alter the natural course of disease and prevent the development of asthma in children with seasonal allergic rhino-conjunctivitis. Two hundred five children aged 6 to 14 years with grass and/or birch pollen allergy were randomized to receive either allergen-specific injection immunotherapy with aluminum-adsorbed native allergen extract subcutaneous immunotherapy for 3 years or to an open control group. Subjects had moderate-to-severe hay fever symptoms, but none of them reported asthma at the time of inclusion. Actively treated children had significantly fewer asthma symptoms after 3 years, as evaluated by clinical diagnosis (odds ratio, 2.52; P < .05). Methacholine bronchial provocation test results were significantly better in the active group. Thus a 3-year course of injection AIT in children with hay fever to grass, birch pollen, or both significantly reduced the risk of asthma.
Lower respiratory tract infections by respiratory syncytial virus (RSV) are the foremost cause of infant hospitalization and are implicated in lasting pulmonary impairment and the development of asthma. Neutrophils infiltrate the airways of pediatric patients with RSV-induced bronchiolitis in vast numbers: approximately 80% of infiltrated cells are neutrophils. However, why neutrophils are recruited to the site of viral respiratory tract infection is not clear. In this review we discuss the beneficial and pathologic contributions of neutrophils to the immune response against RSV infection. Neutrophils can limit viral replication and spread, as well as stimulate an effective antiviral adaptive immune response. However, low specificity of neutrophil antimicrobial armaments allows for collateral tissue damage. Neutrophil-induced injury to the airways during the delicate period of infant lung development has lasting adverse consequences for pulmonary architecture and might promote the onset of asthma in susceptible subjects. We suggest that pharmacologic modulation of neutrophils should be explored as a viable future therapy for severe RSV-induced bronchiolitis and thereby prevent the inception of subsequent asthma. The antiviral functions of neutrophils suggest that targeting of neutrophils in patients with RSV-induced bronchiolitis is best performed under the umbrella of antiviral treatment.
Several risk factors for asthma have been linked with exposures during pregnancy, making their true effects similarly hard to elucidate given the constraints of conducting research in this particular group, and the difficulty of interpreting any findings. A report published in Pediatrics outlined the effects of maternal and infant nutrition on the development of atopic disease (including asthma) in children, reflecting that multiple factors could act in concert to influence disease development. Maternal exposure to vitamin D has been investigated as a risk factor for childhood asthma and wheeze, with conflicting findings; several studies have reported that vitamin D could protect against asthma attacks or prevent worsening asthma symptoms. Many studies have investigated such associations with risk of disease, but the reporting in the media of the study findings often leaves much to be desired in terms of nuance and balance.
Bronchial hyperresponsiveness (BHR) as the main condition for the development of asthma may be modulated either by intrinsic or by extrinsic stimuli as well as by climatic and meteorologic factors. Proinflammatory mediators in combination with alterations of airway mucosa induce or amplify BHR. Upper airway viral infections, exposure to allergens in atopic subjects, chronic hyperplastic changes of the upper airways, airway irritants and analgesics are supposed to be the most likely asthma triggers in predisposed children and adults. There is the suggestion that BHR can be improved not only by treatment with steroidal and nonsteroidal antiinflammatory drugs but also by maritime climatotherapy. The latter could be the result not only of the reduction of inhalative irritants, e.g. of allergen concentration, but also by the involvement or more complex mechanisms. Possible theoretic approaches and hypotheses regarding the mode of action of maritime climatic cures are discussed. First preliminary results obtained in a mediterranean region have demonstrated a negative impact of metereologic events like passages of cold weather fronts or increase of wind velocity on the course of asthma disease. An improvement of BHR assessed by histamine challenge test has been observed at the end of climatotherapy in the Baltic sea area. Prospective studies about asthma prevention in subjects at risk with BHR and atopy that have been starting should contribute to the evaluation of the therapeutic effects and the prognostic importance of maritime climatotherapy for getting exact scientific indications for climatotherapy in patients with bronchial asthma.
Bronchial hyperresponsiveness (BHR) as the main condition for the development of asthma may be modulated either by intrinsic or by extrinsic stimuli as well as by climatic and meteorologic factors. Proinflammatory mediators in combination with alterations of airway mucosa induce or amplify BHR. Upper airway viral infections, exposure to allergens in atopic subjects, chronic hyperplastic changes of the upper airways, airway irritants and analgesics are supposed to be the most likely asthma triggers in predisposed children and adults. There is the suggestion that BHR can be improved not only by treatment with steroidal and nonsteroidal antiinflammatory drugs but also by maritime climatotherapy. The latter could be the result not only of the reduction of inhalative irritants, e.g. of allergen concentration, but also by the involvement or more complex mechanisms. Possible theoretic approaches and hypotheses regarding the mode of action of maritime climatic cures are discussed. First preliminary results obtained in a mediterranean region have demonstrated a negative impact of metereologic events like passages of cold weather fronts or increase of wind velocity on the course of asthma disease. An improvement of BHR assessed by histamine challenge test has been observed at the end of climatotherapy in the Baltic sea area. Prospective studies about asthma prevention in subjects at risk with BHR and atopy that have been starting should contribute to the evaluation of the therapeutic effects and the prognostic importance of maritime climatotherapy for getting exact scientific indications for climatotherapy in patients with bronchial asthma.
With the exception, perhaps, of measures for the avoidance of infrequent forms of asthma caused by very specific types of exposure (e.g., occupational or aspirin-induced asthma), no single action has been irrefutably demonstrated to decrease the risk of the development of persistent asthma in persons who do not already have the disease.
The National Disease Management Program (NDM Program) represents the basic content of structured, cross-sectoral healthcare. In particular, the NDM Program is directed towards coordinating different disciplines and areas of healthcare. The recommendations are developed through interdisciplinary consensus of the scientific medical societies on the basis of the best available evidence. Within this scope the scientific medical societies concerned with the prevention, diagnosis, therapy and rehabilitation of asthma consented upon a National Disease Management Guideline for Asthma in 2005. Among other things, the following cornerstones of asthma prevention were agreed upon: Breastfeeding and non-smoking were suggested as primary prevention measures for (expectant) parents. With respect to secondary prevention, recommendations have been made for allergen avoidance, active/passive smoking and immunotherapy. Regarding tertiary prevention, position statements on vaccination and specific immunotherapy are developed. The present paper presents both the original texts of the recommendations and the evidence underlying them.
Corticosteroids have been used for decades to modulate inflammation therapeutically, yet there is a paucity of data on their effects in humans. We examined the changes in cellular and molecular immune system parameters, or "immunome", in healthy humans after systemic corticosteroid administration. We used multiplexed techniques to query the immunome in 20 volunteers at baseline, and after intravenous hydrocortisone (HC) administered at moderate (250 mg) and low (50 mg) doses, to provide insight into how corticosteroids exert their effects. We performed comprehensive phenotyping of 120 lymphocyte subsets by high dimensional flow cytometry, and observed a decline in circulating specific B and T cell subsets, which reached their nadir 4-8 hours after administration of HC. However, B and T cells rebounded above baseline 24 hours after HC infusion, while NK cell numbers remained stable. Whole transcriptome profiling revealed down regulation of NF-κB signaling, apoptosis, and cell death signaling transcripts that preceded lymphocyte population changes, with activation of NK cell and glucocorticoid receptor signaling transcripts. Our study is the first to systematically characterize the effects of corticosteroids on the human immunome, and we demonstrate that HC exerts differential effects on B and T lymphocytes and natural killer cells in humans. Fauci et al. reported that 400 mg and 100 mg doses of HC cause a transient nadir in circulating peripheral blood lymphocytes at 4–6 hours and recovery to baseline after 24 hours. Our data are consistent with these observations. We also observed differential effects of the two steroid doses on lymphocyte recovery at 24 hours, with total T cells, CD4+ T cells, and B cells rebounding above baseline after the 250 mg dose and total NK cells showing no increase above baseline at 24 hours. HC induced a rapid decline in circulating monocytes and mRNAs related to innate immune signaling as early as one hour after infusion. These effects preceded neutrophil demargination and lymphocyte depletion.
Corticosteroids have been used for decades to modulate inflammation therapeutically, yet there is a paucity of data on their effects in humans. We examined the changes in cellular and molecular immune system parameters, or "immunome", in healthy humans after systemic corticosteroid administration. We used multiplexed techniques to query the immunome in 20 volunteers at baseline, and after intravenous hydrocortisone (HC) administered at moderate (250 mg) and low (50 mg) doses, to provide insight into how corticosteroids exert their effects. We performed comprehensive phenotyping of 120 lymphocyte subsets by high dimensional flow cytometry, and observed a decline in circulating specific B and T cell subsets, which reached their nadir 4-8 hours after administration of HC. However, B and T cells rebounded above baseline 24 hours after HC infusion, while NK cell numbers remained stable. Whole transcriptome profiling revealed down regulation of NF-κB signaling, apoptosis, and cell death signaling transcripts that preceded lymphocyte population changes, with activation of NK cell and glucocorticoid receptor signaling transcripts. Our study is the first to systematically characterize the effects of corticosteroids on the human immunome, and we demonstrate that HC exerts differential effects on B and T lymphocytes and natural killer cells in humans. Fauci et al. reported that 400 mg and 100 mg doses of HC cause a transient nadir in circulating peripheral blood lymphocytes at 4–6 hours and recovery to baseline after 24 hours. Our data are consistent with these observations. We also observed differential effects of the two steroid doses on lymphocyte recovery at 24 hours, with total T cells, CD4+ T cells, and B cells rebounding above baseline after the 250 mg dose and total NK cells showing no increase above baseline at 24 hours. HC induced a rapid decline in circulating monocytes and mRNAs related to innate immune signaling as early as one hour after infusion. These effects preceded neutrophil demargination and lymphocyte depletion.
Lymphocyte kinetic studies employing 51-chromium-labeled autologous lymphocytes were performed in nine normal volunteers in order to determine the effects of hydrocortisone administration on the recirculating versus the nonrecirculating intravascular lymphocyte pools. Following infusion of labeled cells, the recirculating portion of the labeled cells rapidly equilibrated with the total intravascular lymphocyte pool and the vastly larger total-body recirculating lymphocyte pool, so that by 1 hr following infusion 21.8% plus or minus 3.2% of the labeled lymphocytes were left in the circulation. Four hundred milligrams of intravenous hydrocortisone administered 24 hr after infusion of labeled cells caused a profound but transient lymphocytopenia which was maximal at 4 hr with return of lymphocyte counts to normal by 24 hr after injection. Concomitant with the lymphocytopenia there was a dramatic increase in lymphocyte specific activity (cpm per 10-6 lymphocytes), while the total lymphocyte-associated radioactivity remaining in the circulation was unchanged, indicating that corticosteroid administration depleted the unlabeled recirculating cells. As the lymphocyte counts returned to normal following hydrocortisone, the specific activity also returned to normal. These studies indicated that hydrocortisone administration caused a transient lymphocytopenia by a preferential depletion of the recirculating portion of the intravascular lymphocyte pool.
The mechanisms and kinetics of the immunosuppressive effects of alternate-day prednisone were investigated in a group of patients with a variety of inflammatory diseases receiving a range of alternate-day prednisone doses from 5 to 120 mg. Total circulating lymphocyte and monocyte counts, as well as proportions of lymphocyte subpopulations defined both by surface markers and by in vitro functional capacities, were studied. At 8 a. m. of the day on prednisone, just before drug administration, lymphocyte and monocyte counts, proportions of lymphocyte subpopulations, as well as in vitro lymphocyte blastogenic responses to various mitogenic and antigenic stimuli were normal. 4 h after the administration of prednisone, there was a profound lymphocytopenia and monocytopenia, with a differential depletion of thymus-derived lymphocytes as well as various functionally defined lymphocyte subpopulations. Lymphocyte kinetic studies using a radioactive chromium-labeled autologous lymphocytes showed that the lymphocytopenia was due predominantly to a transient depletion of the recirculating portion of the intravascular lymphocytepool. All these parameters returned to normal by 8 a.m. of the following day (off prednisone) and remained normal throughout the day. This very transient lymphocytopenia and monocytopenia after prednisone, with normal cell numbers, proportions, and functions throughout the remainder of the 2-day cycle, was associated with suppression of disease activity, yet did not affect cutaneous delayed hypersensitivity in these patients nor increase the likelihood of infectious complications. This drug-associated cyclic and transient monocytopenia and selective lymphocytopenia is best explained by a redistribution of recirculating lymphocytes to other body compartments, particularly the bone marrow.
The growth of knowledge in the field of the pharmacokinetics of prednisolone/prednisone has been slow for several reasons. First, convenient and specific methods for measuring these steroids only became available with the development of high performance liquid chromatographic methods. Secondly, prednisolone is nonlinearly bound to transcortin and albumin: since the unbound concentrations of prednisolone are biologically relevant, it was necessary to determine the free fraction in each plasma sample. Thirdly, due to the short half-life of prednisolone no steady-state is achieved, and therefore area under the concentration-time curve needed to be determined in all studies. Fourthly, prednisolone and prednisone are interconvertible and prednisolone is given intravenously as an ester prodrug, features which created controversies about the correct interpretation of pharmacokinetic results. Finally, the total body clearances of total and (to a lesser degree) of unbound prednisolone increase with increasing concentrations of prednisolone. Therefore, in order to compare pharmacokinetic results between different subjects, standardised doses had to be administered. The investigations performed so far have revealed that: (1) the dose-dependent pharmacokinetics partly explain the clinical observation that an alternate-day regimen with prednisone yields fewer biological effects; (2) the interconversion of prednisone into prednisolone is not a limiting factor, even in patients with severely impaired liver function; (3) hypoproteinaemia per se does not cause increased unbound concentrations of prednisolone in vivo; (4) patients with liver failure, renal failure or a renal transplant, subjects older than 65 years, women on estrogen-containing oral contraceptive steroids or subjects taking ketoconazole have increased unbound concentrations of prednisolone-whereas hyperthyroid patients, some patients with Crohn's disease, subjects taking microsomal liver enzyme-inducing agents or patients on intravenous prednisolone phthalate (instead of prednisolone phosphate) or on some brands of enteric coated prednisolone tablets have decreased concentrations of prednisolone. The biological relevance of the altered pharmacokinetics is supported in part by altered clinical effects and altered effects on cellular immunofunctions.
The growth of knowledge in the field of the pharmacokinetics of prednisolone/prednisone has been slow for several reasons. First, convenient and specific methods for measuring these steroids only became available with the development of high performance liquid chromatographic methods. Secondly, prednisolone is nonlinearly bound to transcortin and albumin: since the unbound concentrations of prednisolone are biologically relevant, it was necessary to determine the free fraction in each plasma sample. Thirdly, due to the short half-life of prednisolone no steady-state is achieved, and therefore area under the concentration-time curve needed to be determined in all studies. Fourthly, prednisolone and prednisone are interconvertible and prednisolone is given intravenously as an ester prodrug, features which created controversies about the correct interpretation of pharmacokinetic results. Finally, the total body clearances of total and (to a lesser degree) of unbound prednisolone increase with increasing concentrations of prednisolone. Therefore, in order to compare pharmacokinetic results between different subjects, standardised doses had to be administered. The investigations performed so far have revealed that: (1) the dose-dependent pharmacokinetics partly explain the clinical observation that an alternate-day regimen with prednisone yields fewer biological effects; (2) the interconversion of prednisone into prednisolone is not a limiting factor, even in patients with severely impaired liver function; (3) hypoproteinaemia per se does not cause increased unbound concentrations of prednisolone in vivo; (4) patients with liver failure, renal failure or a renal transplant, subjects older than 65 years, women on estrogen-containing oral contraceptive steroids or subjects taking ketoconazole have increased unbound concentrations of prednisolone-whereas hyperthyroid patients, some patients with Crohn's disease, subjects taking microsomal liver enzyme-inducing agents or patients on intravenous prednisolone phthalate (instead of prednisolone phosphate) or on some brands of enteric coated prednisolone tablets have decreased concentrations of prednisolone. The biological relevance of the altered pharmacokinetics is supported in part by altered clinical effects and altered effects on cellular immunofunctions.
Six healthy male volunteers were given 5, 20, and 50 mg of oral prednisone and 5, 20, and 400 mg doses of intravenous prednisolone. Plasma and urine concentrations of prednisone and prednisolone were determined by HPLC, and the binding of prednisolone to plasma proteins was measured by radioisotopic and equilibrium dialysis techniques. The pharmacokinetics of both oral prednisone and intravenous prednisolone were dose-dependent. The mean oral dose plasma clearances of prednisone ranged from 572 ml/min/1.73 m 2 for the 5 mg dose to 2271 ml/min/1.73 m 2 for the 50 mg dose. Changes in prednisone half-life were insignificant, but increases in the half-life of its metabolite were dose-dependent. The systemic plasma clearance of i.v. prednisolone was dose-dependent and increased from 111 to 194 ml/min/1.73 m 2 over the 5 to 40 mg i.v. dosage range. The steady-state volume of distribution also increased, but little change in mean transit time and half-life was found. The binding of prednisolone to plasma proteins was markedly concentration-dependent, and a two compartment, nonlinear equation was used to characterize the effective binding of prednisolone to transcortin and albumin. The apparent pharmacokinetic parameters of protein-free and transcortin-free prednisolone were relatively constant with dose. The interconversion of prednisone and prednisolone varied with time and dose, although prednisolone concentrations dominated by 4- to 10-fold over prednisone. In urine, 2-5% of either administered drug was excreted as prednisone and 11-24% as prednisolone. The apparent renal clearances of both steroids were also nonlinear and unrelated to protein binding. These studies indicate that the pharmacokinetics of prednisone and prednisolone are dose-dependent and that protein binding does not fully explain their apparent nonlinear distribution and disposition.
In rheumatoid arthritis (RA), nocturnal release of proinflammatory cytokines is not adequately counteracted by endogenous glucocorticoid and is associated with symptoms of morning stiffness and pain. Taking exogenous glucocorticoid during the night reduces morning stiffness significantly more than treatment at the conventional time in the morning, although waking to take tablets is unacceptable for patients. Modified-release prednisone tablets were developed to allow administration at bedtime for programmed delivery of glucocorticoid during the night. Single-center crossover studies were conducted, each in ≤24 healthy subjects, to compare the pharmacokinetics of a single 5-mg oral dose of modified-release prednisone and conventional prednisone, as well as the effect of food on bioavailability. There was no substantial difference in pharmacokinetic parameters of the formulations apart from the programmed delay in release of glucocorticoid from the modified-release tablets (C(max) 97%, AUC(0-∞) 101%, 90% confidence intervals within the requisite range for bioequivalence). Administration after a full or light meal did not affect pharmacokinetic characteristics, but bioavailability was reduced under fasted conditions. Pharmacokinetic evaluation in 9 patients with RA confirmed that modified-release prednisone tablets taken at bedtime (around 22:00 h) with or after an evening meal result in programmed release of glucocorticoid 4 to 6 hours after intake.
Background: Renal transplant recipients were noted to appear cushingoid while on low doses of steroid as part of a triple therapy immunosuppression of cyclosporin A (CsA), prednisolone, and azathioprine. Methods: The study group comprised adult renal transplant recipients with stable graft function who had received their renal allograft a minimum of 1 year previously (43 studies undertaken in 22 men and 20 women) with median daily prednisone dose of 7 mg (range 3-10). The control group was healthy nontransplant subjects [median dose 10 mg (10-30)]. Prednisolone bioavailability was measured using a limited 6-hour area under the curve (AUC), with prednisolone measured using specific HPLC assay. Results: The median prednisolone AUC/mg dose for all transplant recipients was significantly greater than the control group by approximately 50% (316 nmol x h/L/mg prednisolone versus 218). AUC was significantly higher in female recipients (median 415 versus 297 for men) and in recipients receiving cyclosporin (348 versus 285). The highest AUC was in women on estrogen supplements who were receiving cyclosporin (median 595). A significantly higher proportion of patients on triple therapy had steroid side effects compared with those on steroid and azathioprine (17/27 versus 4/15), more women than men had side effects (14/16 versus 7/22), and the AUC/mg prednisone was greater in those with side effects than without (median 377 versus 288 nmol x h/L/mg). Discussion: The results are consistent with the hypothesis that CsA increases the bioavailability of prednisolone, most likely through inhibition of P-glycoprotein. The increased exposure to steroid increased the side-effect profile of steroids in the majority of patients. Because the major contributor to AUC is the maximum postdose concentration, it may be possible to use single-point monitoring (2 hours postdose) for routine clinical studies.
Background: Renal transplant recipients were noted to appear cushingoid while on low doses of steroid as part of a triple therapy immunosuppression of cyclosporin A (CsA), prednisolone, and azathioprine. Methods: The study group comprised adult renal transplant recipients with stable graft function who had received their renal allograft a minimum of 1 year previously (43 studies undertaken in 22 men and 20 women) with median daily prednisone dose of 7 mg (range 3-10). The control group was healthy nontransplant subjects [median dose 10 mg (10-30)]. Prednisolone bioavailability was measured using a limited 6-hour area under the curve (AUC), with prednisolone measured using specific HPLC assay. Results: The median prednisolone AUC/mg dose for all transplant recipients was significantly greater than the control group by approximately 50% (316 nmol x h/L/mg prednisolone versus 218). AUC was significantly higher in female recipients (median 415 versus 297 for men) and in recipients receiving cyclosporin (348 versus 285). The highest AUC was in women on estrogen supplements who were receiving cyclosporin (median 595). A significantly higher proportion of patients on triple therapy had steroid side effects compared with those on steroid and azathioprine (17/27 versus 4/15), more women than men had side effects (14/16 versus 7/22), and the AUC/mg prednisone was greater in those with side effects than without (median 377 versus 288 nmol x h/L/mg). Discussion: The results are consistent with the hypothesis that CsA increases the bioavailability of prednisolone, most likely through inhibition of P-glycoprotein. The increased exposure to steroid increased the side-effect profile of steroids in the majority of patients. Because the major contributor to AUC is the maximum postdose concentration, it may be possible to use single-point monitoring (2 hours postdose) for routine clinical studies.
The effects of single oral doses of 10, 15, or 30 mg of prednisone on circulating mononuclear cells, autologous MLR, mitogen responses, and allogeneic MLR were studied in healthy volunteers. Doses as low as 10 mg were immunosuppressive, causing diminution of circulating T cells and monocytes, and significant reduction in autologous but not allogeneic MLR responses. These effects were maximal 6 hr after drug administration and gone by 24 hr. Autologous MLR responses were particularly sensitive to the effects of prednisone being significantly and consistently suppressed 2 hr after drug administration, before significant cell redistribution had occurred. Macrophage-enriched stimulating cells were more easily suppressed than responding T cells. Since the autologous MLR may be important in in vivo regulation of immune responses, its reduction by low-dose glucocorticoids may be of clinical relevance. This suppressive effect must be considered in studies of the autologous MLR in patients receiving glucocorticoid therapy.
The aim of this study was to estimate the influence of corticosteroids on Th1 and Th2 serum cytokine balance in patients with GO: IFNgamma, TNFalpha, IL-4 and IL-10. Further, we tested the hypothesis of an up-regulation of Th2 immune response during successful treatment with corticosteroids to explain their beneficial effect in Graves' ophthalmopathy. Serum cytokines were detected in three groups of subjects: 20 patients with Graves' disease without ophthalmopathy (Gd), 16 patients with clinical symptoms of ophthalmopathy (GO) (CAS over 3 points, last consultation record for GO less than a year old) and 16 healthy volunteers. Corticosteroid therapy consisted of intravenous infusions of methylprednisolone (MP) (2 series, 3 g each time) and subsequent treatment with oral prednisone (60 mg per day) in a tapering schedule. The serum samples were collected 24 hours before MP, 24 hours after MP, 14 days of treatment with prednisone and at the end of corticosteroid therapy. The levels of IFNgamma, TNFalpha, IL-4 and IL-10 in the serum were determined using ELISA. Statistical significance was estimated by the Mann-Whitney U-test. Our findings show a deviation to systemic Th2 profile cytokines in Graves' disease. In patients with GO, we found a significantly increased serum IL-10 concentration. In corticosteroid-responsive patients, the balance of serum cytokines IL-4/IFNgamma, IL-4/TNFalpha, IL-10/IFNgamma and IL-10/TN Falpha increased and remained upregulated until the end of the study. In non-responders, the balance of serum cytokines studied increased after methylprednisolone but declined markedly during continuation of the therapy with prednisone. In summary, our results show that efficient corticosteroid therapy may be related to its influence on Th2/Th1 profile cytokine balance. The upregulation of serum IL-4 and IL-10 during successful treatment with corticosteroids indicate the possibility of using these cytokines as predictors of the beneficial effect of corticosteroids in Graves' ophthalmopathy.
It is thought that glucocorticosteroids impair the clearance of immune complexes by the mononuclear phagocyte system (MPS). We studied the effect of a five day course of prednisone (1 mg/kg body weight per day) on MPS function in 10 healthy volunteers, using soluble radiolabeled aggregates of human immunoglobulin G as a probe. MPS function was assessed before steroid treatment, and again 24 hours after the last dose of prednisone. Elimination kinetics and the uptake of the immunoglobulin aggregates by liver and spleen did not change after prednisone treatment. This suggests that, in contrast to general belief, high doses of glucocorticosteroids have no direct, acute effect on MPS function.
Birt-Hogg-Dubé syndrome (BHD) is a rare autosomal dominant disorder caused by mutations in the Folliculin gene and is characterized by the formation of fibrofolliculomas, early onset renal cancers, pulmonary cysts, and spontaneous pneumothoraces. The exact pathogenesis of tumor and lung cyst formation in BHD remains unclear. There is great phenotypic variability in the clinical features of BHD, and patients can present with any combination of skin, pulmonary, or renal findings. More than 80% of adult patients with BHD have pulmonary cysts on high-resolution computed tomography scan of the chest.
Birt-Hogg-Dubé syndrome (BHD) is a rare autosomal dominant disorder caused by mutations in the Folliculin gene and is characterized by the formation of fibrofolliculomas, early onset renal cancers, pulmonary cysts, and spontaneous pneumothoraces. The exact pathogenesis of tumor and lung cyst formation in BHD remains unclear. There is great phenotypic variability in the clinical features of BHD, and patients can present with any combination of skin, pulmonary, or renal findings. More than 80% of adult patients with BHD have pulmonary cysts on high-resolution computed tomography scan of the chest.
Background and objective: The purpose of this study was to create a practical CT-based algorithm to differentiate Birt-Hogg-Dubé (BHD) syndrome from other diffuse cystic lung diseases (DCLD). Methods: The study was a retrospective review of the CT images of 33 patients with BHD syndrome, 33 patients with LAM, and 23 patients with NBNL (non-BHD and non-LAM) among DCLD patients. On the basis of the data collected, the CT images were reviewed again to evaluate the characteristics (size, number, distribution, and morphology) of pulmonary cysts. Results: Lower lung-predominant cysts were more likely to be found in patients with BHD syndrome than in patients with LAM or in the NBNL DCLD group. In the axial distribution, 18 of 33 patients in BHD group had cysts that were predominantly near the mediastinum, and all the patients in the LAM and NBNL DCLD groups had diffuse cysts. The appearance of fusiform cysts was more easily observed in patients in the BHD group. In total, 58% patients in the BHD group had less than 50 lung cysts, while all patients in the non-BHD group had more than 50 lung cysts. The biggest cyst was located in the lower lobe in 28 of 33 patients in the BHD group, while 11 of 33 patients in LAM group and 10 patients in the NBNL DCLD group had the biggest cyst in the lower lobe. Conclusion: The pulmonary cysts in patients with BHD tended to be fusiform, less numerous and located predominantly in the lower lobe and near the mediastinum. These radiologic pulmonary features could assist physicians in differentiating BHD from other DCLDs.
Birt-Hogg-Dubé syndrome (BHD) is an autosomal dominant condition characterised clinically by skin fibrofolliculomas, pulmonary cysts, spontaneous pneumothorax, and renal cancer. The condition is caused by germline mutations in the FLCN gene, which encodes folliculin; the function of this protein is largely unknown, although FLCN has been linked to the mTOR pathway. The availability of DNA-based diagnosis has allowed insight into the great variation in expression of FLCN, both within and between families. Patients can present with skin signs and also with pneumothorax or renal cancer. Preventive measures are aimed mainly at early diagnosis and treatment of renal cancer. This Review gives an overview of current diagnosis and management of BHD.
Germline mutations in the novel tumor suppressor gene FLCN are responsible for the autosomal dominant inherited disorder Birt-Hogg-Dubé (BHD) syndrome that predisposes to fibrofolliculomas, lung cysts and spontaneous pneumothorax, and an increased risk for developing kidney tumors. Although the encoded protein, folliculin (FLCN), has no sequence homology to known functional domains, x-ray crystallographic studies have shown that the C-terminus of FLCN has structural similarity to DENN (differentially expressed in normal cells and neoplasia) domain proteins that act as guanine nucleotide exchange factors (GEFs) for small Rab GTPases. FLCN forms a complex with folliculin interacting proteins 1 and 2 (FNIP1, FNIP2) and with 5' AMP-activated protein kinase (AMPK). This review summarizes FLCN functional studies which support a role for FLCN in diverse metabolic pathways and cellular processes that include modulation of the mTOR pathway, regulation of PGC1α and mitochondrial biogenesis, cell-cell adhesion and RhoA signaling, control of TFE3/TFEB transcriptional activity, amino acid-dependent activation of mTORC1 on lysosomes through Rag GTPases, and regulation of autophagy. Ongoing research efforts are focused on clarifying the primary FLCN-associated pathway(s) that drives the development of fibrofolliculomas, lung cysts and kidney tumors in BHD patients carrying germline FLCN mutations.
Germline mutations in the novel tumor suppressor gene FLCN are responsible for the autosomal dominant inherited disorder Birt-Hogg-Dubé (BHD) syndrome that predisposes to fibrofolliculomas, lung cysts and spontaneous pneumothorax, and an increased risk for developing kidney tumors. Although the encoded protein, folliculin (FLCN), has no sequence homology to known functional domains, x-ray crystallographic studies have shown that the C-terminus of FLCN has structural similarity to DENN (differentially expressed in normal cells and neoplasia) domain proteins that act as guanine nucleotide exchange factors (GEFs) for small Rab GTPases. FLCN forms a complex with folliculin interacting proteins 1 and 2 (FNIP1, FNIP2) and with 5' AMP-activated protein kinase (AMPK). This review summarizes FLCN functional studies which support a role for FLCN in diverse metabolic pathways and cellular processes that include modulation of the mTOR pathway, regulation of PGC1α and mitochondrial biogenesis, cell-cell adhesion and RhoA signaling, control of TFE3/TFEB transcriptional activity, amino acid-dependent activation of mTORC1 on lysosomes through Rag GTPases, and regulation of autophagy. Ongoing research efforts are focused on clarifying the primary FLCN-associated pathway(s) that drives the development of fibrofolliculomas, lung cysts and kidney tumors in BHD patients carrying germline FLCN mutations.
Objective: Birt-Hogg-Dubé (BHD) syndrome is an autosomal dominant inherited syndrome involving multiple organs. In young patients, renal neoplasms that are multiple, bilateral, or both, such as oncocytomas, chromophobe renal cell carcinoma (RCC), hybrid chromophobe RCC-oncocytomas, clear cell RCC, and papillary RCC, can suggest BHD syndrome. Extrarenal findings, including dermal lesions, pulmonary cysts, and spontaneous pneumothoraces, also aid in diagnosis. Conclusion: Radiologists may be one of the first medical specialists to suggest the diagnosis of BHD syndrome. Knowledge of pathogenesis and management, including the importance of the types of renal neoplasms in a given patient, is needed to properly recognize this rare condition.
Loss-of-function mutations in the folliculin gene (FLCN) on chromosome 17p cause Birt-Hogg-Dube syndrome (BHD), which is associated with cystic lung disease. The risk of lung collapse (pneumothorax) in BHD patients is 50-fold higher than in the general population. The cystic lung disease in BHD is distinctive because the cysts tend to be basilar, subpleural and lentiform, differentiating BHD from most other cystic lung diseases. Recently, major advances in elucidating the primary functions of the folliculin protein have been made, including roles in mTOR and AMPK signaling via the interaction of FLCN with FNIP1/2, and cell-cell adhesion via the physical interaction of FLCN with plakophilin 4 (PKP4), an armadillo-repeat containing protein that interacts with E-cadherin and is a component of the adherens junctions. In addition, in just the last three years, the pulmonary impact of FLCN deficiency has been examined for the first time. In mouse models, evidence has emerged that AMPK signaling and cell-cell adhesion are involved in alveolar enlargement. In addition, the pathologic features of human BHD cysts have been recently comprehensively characterized. The "stretch hypothesis" proposes that cysts in BHD arise because of fundamental defects in cell-cell adhesion, leading to repeated respiration-induced physical stretch-induced stress and, over time, expansion of alveolar spaces particularly in regions of the lung with larger changes in alveolar volume and at weaker "anchor points" to the pleura. This hypothesis ties together many of the new data from cellular and mouse models of BHD and from the human pathologic studies. Critical questions remain. These include whether the consequences of stretch-induced cyst formation arise through a destructive/inflammatory program or a proliferative program (or both), whether cyst initiation involves a "second hit" genetic event inactivating the remaining wild-type copy of FLCN (as is known to occur in BHD-associated renal cell carcinomas), and whether cyst initiation involves exclusively the epithelial compartment versus an interaction between the epithelium and mesenchyme. Ultimately, understanding the mechanisms of cystic lung disease in BHD may help to elucidate the pathogenesis of primary spontaneous pneumothorax, with more than 20,000 cases reported annually in the United States alone.
Birt-Hogg-Dubé syndrome (BHD) is a rare inherited autosomal dominant disorder caused by germline mutations in the tumour suppressor gene FLCN, encoding the protein folliculin. Its clinical expression typically includes multiple pulmonary cysts, recurrent spontaneous pneumothoraces, cutaneous fibrofolliculomas and renal tumours of various histological types. BHD has no sex predilection and tends to manifest in the third or fourth decade of life. Multiple bilateral pulmonary cysts are found on chest computed tomography in >80% of patients and more than half experience one or more episodes of pneumothorax. A family history of pneumothorax is an important clue, which suggests the diagnosis of BHD. Unlike other cystic lung diseases such as lymphangioleiomyomatosis and pulmonary Langerhans cell histiocytosis, BHD does not lead to progressive loss of lung function and chronic respiratory insufficiency. Renal tumours affect about 30% of patients during their lifetime, and can be multiple and recurrent. The diagnosis of BHD is based on a combination of genetic, clinical and/or skin histopathological criteria. Management mainly consists of early pleurodesis in the case of pneumothorax, periodic renal imaging for tumour detection, and diagnostic work-up in search of BHD in relatives of the index patient.
Birt-Hogg-Dubé syndrome (BHD) is a rare inherited autosomal dominant disorder caused by germline mutations in the tumour suppressor gene FLCN, encoding the protein folliculin. Its clinical expression typically includes multiple pulmonary cysts, recurrent spontaneous pneumothoraces, cutaneous fibrofolliculomas and renal tumours of various histological types. BHD has no sex predilection and tends to manifest in the third or fourth decade of life. Multiple bilateral pulmonary cysts are found on chest computed tomography in >80% of patients and more than half experience one or more episodes of pneumothorax. A family history of pneumothorax is an important clue, which suggests the diagnosis of BHD. Unlike other cystic lung diseases such as lymphangioleiomyomatosis and pulmonary Langerhans cell histiocytosis, BHD does not lead to progressive loss of lung function and chronic respiratory insufficiency. Renal tumours affect about 30% of patients during their lifetime, and can be multiple and recurrent. The diagnosis of BHD is based on a combination of genetic, clinical and/or skin histopathological criteria. Management mainly consists of early pleurodesis in the case of pneumothorax, periodic renal imaging for tumour detection, and diagnostic work-up in search of BHD in relatives of the index patient.
Birt-Hogg-Dubé syndrome (BHD) is an autosomal dominant genetic disorder characterised by pulmonary cysts, fibrofolliculomas and renal tumours. The pulmonary cysts may lead to pneumothorax, and in cases of primary, spontaneous pneumothorax the syndrome should be excluded. The renal tumours are frequently malignant, but slow-growing. Screening and family assessment enable discovery of renal cancer at an early stage. The syndrome is underdiagnosed and little known.
Birt-Hogg-Dubé (BHD) syndrome is an autosomal dominant disorder caused by germline loss-of-function mutations in Folliculin gene (FLCN). BHD is characterized by lower lobe-predominant pulmonary cysts with risk of pneumothorax, benign skin tumors (fibrofolliculomas), and renal cell carcinoma, often of an unusual chromophobe/oncocytic hybrid histology. The FLCN protein functions in multiple signaling and metabolic pathways including positive regulation of mechanistic target of rapamycin complex 1 (mTORC1) activity via FLCN's GTPase (GAP) activity for Rag C, positive regulation of Wnt signaling (in mesenchymal cells), and negative regulation of TFE3 nuclear localization. Therefore, FLCN-deficient cells are predicted to have reduced mTORC1 and Wnt activity and enhanced TFE3 activity. Folliculin also has functions in autophagy, mitochondrial biogenesis, cell-cell adhesion, 5' AMP activated protein kinase activity, and other pathways. The specific contributions of these pathways to the lung manifestations of BHD are largely unknown. This review is focused on the pulmonary manifestations of BHD, highlighting selected recent advances in elucidating the cellular functions of FLCN and current hypotheses related to the pathogenesis of cystic lung disease in BHD, including the "stretch hypothesis." We also discuss important knowledge gaps in the field, including the genetic, cellular and physical mechanisms of cyst pathogenesis, and the timing of cyst initiation, which may occur during lung development.
Birt-Hogg-Dubé syndrome (BHD) is a rare, autosomal dominant disorder characterized by the development of hair follicle tumors, renal tumors and pulmonary cysts. BHD is caused by heterozygous, predominantly truncating mutations in the folliculin (FLCN) gene located on chromosome 17, which encodes a highly conserved tumor suppressor protein. Although management of renal tumors of low malignant potential is the primary focus of longitudinal care, pulmonary manifestations including cyst formation and spontaneous pneumothorax are among the most common manifestations in BHD. Due to the lack of awareness, there is commonly a delay in the pulmonary diagnosis of BHD and patients are frequently mislabeled as having chronic obstructive lung disease, emphysema or common bullae/blebs. A family history of pneumothorax is present in 35 % of patients with BHD. Certain imaging characteristics of the cysts, including size, basilar and peripheral predominance, perivascular and periseptal localization, and elliptical or lentiform shape can suggest the diagnosis of BHD based on inspection of the chest CT scan alone. Recurrent pneumothoraces are common and early pleurodesis is recommended. A better understanding of role of FLCN in pulmonary cyst formation and long term studies to define the natural history of the pulmonary manifestations of BHD are needed.
Birt-Hogg-Dubé syndrome (BHD) is a rare, autosomal dominant disorder characterized by the development of hair follicle tumors, renal tumors and pulmonary cysts. BHD is caused by heterozygous, predominantly truncating mutations in the folliculin (FLCN) gene located on chromosome 17, which encodes a highly conserved tumor suppressor protein. Although management of renal tumors of low malignant potential is the primary focus of longitudinal care, pulmonary manifestations including cyst formation and spontaneous pneumothorax are among the most common manifestations in BHD. Due to the lack of awareness, there is commonly a delay in the pulmonary diagnosis of BHD and patients are frequently mislabeled as having chronic obstructive lung disease, emphysema or common bullae/blebs. A family history of pneumothorax is present in 35 % of patients with BHD. Certain imaging characteristics of the cysts, including size, basilar and peripheral predominance, perivascular and periseptal localization, and elliptical or lentiform shape can suggest the diagnosis of BHD based on inspection of the chest CT scan alone. Recurrent pneumothoraces are common and early pleurodesis is recommended. A better understanding of role of FLCN in pulmonary cyst formation and long term studies to define the natural history of the pulmonary manifestations of BHD are needed.
Background: Coronavirus disease (COVID-19) has affected more than 100 countries worldwide and the discharge criteria of patients with COVID-19 vary across different countries. In China, patients with two negative respiratory viral RNA tests taken at least one day apart can be discharged with no further quarantine required. Currently, PCR testing of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in fecal sample is not routinely performed. Methods: We present a patient with COVID-19, whose respiratory swabs became negative but fecal sample remained positive for SARS-CoV-2 RNA. Results: Stool sample collected on 27th of February was still positive for SARS-CoV-2 RNA, 24 days after the first negative respiratory swab. Conclusions: Based on the experience from the 2003 SARS epidemic, we recommend that fecal RNA testing of SARS-CoV-2 should be incorporated into the discharge criteria to minimize the risk of transmission from the gastrointestinal tract.
Background: Coronavirus disease (COVID-19) has affected more than 100 countries worldwide and the discharge criteria of patients with COVID-19 vary across different countries. In China, patients with two negative respiratory viral RNA tests taken at least one day apart can be discharged with no further quarantine required. Currently, PCR testing of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) in fecal sample is not routinely performed. Methods: We present a patient with COVID-19, whose respiratory swabs became negative but fecal sample remained positive for SARS-CoV-2 RNA. Results: Stool sample collected on 27th of February was still positive for SARS-CoV-2 RNA, 24 days after the first negative respiratory swab. Conclusions: Based on the experience from the 2003 SARS epidemic, we recommend that fecal RNA testing of SARS-CoV-2 should be incorporated into the discharge criteria to minimize the risk of transmission from the gastrointestinal tract.
Background: Nucleic acid persists after symptom resolution and infectivity for many viral infections via delayed clearance of nucleic acid fragments, non-infectious particles, or transmissible virus. For Coronavirus Disease 2019 (COVID-19), the relationship between nasopharyngeal (NP) swab positivity, the development of antibodies against COVID-19, and clinical history are unclear. Study design and methods: Individuals who recovered from COVID-19 and volunteered to donate convalescent plasma (CP) were screened by NP swab PCR, responded to a questionnaire, and were tested for anti-COVID-19 antibodies. Results: A proportion of 11.8% of individuals tested positive for SARS-CoV-2 by NP swab PCR greater than 14 days after the resolution of symptoms of active disease, including one donor who had asymptomatic disease and tested positive by NP swab 41 days after her initial diagnosis. Clinical history did not show a significant correlation with persistence of NP swab positivity. Also, NP swab positivity >14 days from symptom resolution did not correlate with anti-COVID-19 serology results. IgG anti-SARS-CoV-2 spike antibody strength correlated with hospitalization for COVID-19 using two different assays. Total anti-SARS-CoV-2 nucleocapsid antibody strength correlated with time from symptom resolution to sample collection and symptom duration. Conclusions: SARS-CoV-2 nucleic acid is detectable long after the resolution of symptoms in a significant percentage of previously diagnosed individuals, which is important to consider when interpreting PCR swab results. Persistence of PCR positivity does not correlate with antibody strength or symptoms of COVID-19. If anti-spike antibody is used to assess CP potency, individuals who suffered severe COVID-19 disease symptoms may represent better donors.
Background: Coronavirus disease 2019 (COVID-19) convalescent plasma (CCP) collection began in two Brazilian hospitals for treatment of severe/critical patients. Methods and materials: Mild/moderate COVID-19 convalescents were selected as CCP donors after reverse transcription polymerase chain reaction (RT-PCR) confirmed severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection and absence of symptoms for ≥14 days plus (a) age (18-60 years), body weight greater than 55 kg; (b) immunohematological studies; (c) no infectious markers of hepatitis B virus, hepatitis C virus, human immunodeficiency virus, human T-lymphotropic virus-1/2, Chagas and syphilis infection; (d) no HLA antibodies (multiparous); (e) second RT-PCR (nasopharyngeal swab and/or blood) negativity; (f) virus neutralization test (cytopathic effect-based virus neutralization test neutralizing antibody) and anti-nucleocapsid protein SARS-CoV-2 IgM, IgG, and IgA enzyme-linked immunosorbent assays. Results: Among 271 donors (41 females, 230 males), 250 presented with neutralizing antibodies. Final RT-PCR was negative on swab (77.0%) or blood (88.4%; P = .46). Final definition of RT-PCR was only defined at more than 28 days after full recovery in 59 of 174 (33.9%) RT-PCR -ve, and 25/69 RT-PCR +ve (36.2%; 13 between 35 and 48 days). Neutralizing antibody titers of 160 or greater were found in 63.6%. Correlation between IgG signal/cutoff of 5.0 or greater and neutralizing antibody of 160 or greater was 82.4%. Combination of final RT-PCR -ve with neutralizing antibody ≥160 was 41.3% (112/271). Serial plasma collection showed decline in neutralizing antibody titers and IgA levels (P < .05), probably denoting a "golden period" for CCP collection (≤28 days after joining the program); IgA might have an important role as neutralizing antibody. Donor's weight, days between disease onset and serial plasma collection, and IgG and IgM levels are important predictors for neutralizing antibody titer. Conclusions: RT-PCR +ve cases are still detected in 36.2% within 28 to 48 days after recovery. High anti-nucleocapsid protein IgG levels may be used as a surrogate marker to neutralizing antibody.
Background: Reverse-transcription PCR (RT-PCR) assays are used to test for infection with the SARS-CoV-2 virus. RT-PCR tests are highly specific and the probability of false positives is low, but false negatives are possible depending on swab type and time since symptom onset. Aim: To determine how the probability of obtaining a false-negative test in infected patients is affected by time since symptom onset and swab type. Methods: We used generalised additive mixed models to analyse publicly available data from patients who received multiple RT-PCR tests and were identified as SARS-CoV-2 positive at least once. Results: The probability of a positive test decreased with time since symptom onset, with oropharyngeal (OP) samples less likely to yield a positive result than nasopharyngeal (NP) samples. The probability of incorrectly identifying an uninfected individual due to a false-negative test was considerably reduced if negative tests were repeated 24 hours later. For a small false-positive test probability (<0.5%), the true number of infected individuals was larger than the number of positive tests. For a higher false-positive test probability, the true number of infected individuals was smaller than the number of positive tests. Conclusion: NP samples are more sensitive than OP samples. The later an infected individual is tested after symptom onset, the less likely they are to test positive. This has implications for identifying infected patients, contact tracing and discharging convalescing patients who are potentially still infectious.
Background: Reverse-transcription PCR (RT-PCR) assays are used to test for infection with the SARS-CoV-2 virus. RT-PCR tests are highly specific and the probability of false positives is low, but false negatives are possible depending on swab type and time since symptom onset. Aim: To determine how the probability of obtaining a false-negative test in infected patients is affected by time since symptom onset and swab type. Methods: We used generalised additive mixed models to analyse publicly available data from patients who received multiple RT-PCR tests and were identified as SARS-CoV-2 positive at least once. Results: The probability of a positive test decreased with time since symptom onset, with oropharyngeal (OP) samples less likely to yield a positive result than nasopharyngeal (NP) samples. The probability of incorrectly identifying an uninfected individual due to a false-negative test was considerably reduced if negative tests were repeated 24 hours later. For a small false-positive test probability (<0.5%), the true number of infected individuals was larger than the number of positive tests. For a higher false-positive test probability, the true number of infected individuals was smaller than the number of positive tests. Conclusion: NP samples are more sensitive than OP samples. The later an infected individual is tested after symptom onset, the less likely they are to test positive. This has implications for identifying infected patients, contact tracing and discharging convalescing patients who are potentially still infectious.
In the ongoing coronavirus disease 2019 (COVID-19) pandemic, one potential cause of concern is that some discharged COVID-19 patients are testing positive again for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) RNA. To better understand what is happening and to provide public health policy planners and clinicians timely information, we have searched and reviewed published studies about discharged patients testing positive again for the SARS-CoV-2 RNA. Our search found 12 reports, all of which described patients in China. Our review of these reports indicates the presence of discharged patients who remain asymptomatic but test positive. However, it is unclear whether they are contagious because a positive reverse transcriptase - polymerase chain reaction (RT- PCR) test does not necessarily indicate the presence of replicating and transmissible virus. Our review suggests the need for timely, parallel testing of different samples, including, for example, fecal specimens, from COVID-19 patients before and after they are discharged from hospitals.
Many studies have shown that re-positive tests for SARS-CoV-2 by RT-PCR in recovered COVID-19 patients are very common. We aim to conduct this review to summarize the clinical and epidemiological characteristics of these patients and discuss the potential explanations for recurrences, the contagiousness of re-detectable positive SARS-CoV-2 virus, and the management of COVID-19 patients after discharge from hospital. The proportion of re-positive tests in discharged COVID-19 patients varied from 2.4 to 69.2% and persisted from 1 to 38 days after discharge, depending on population size, age of patients, and type of specimens. Currently, several causes of re-positive tests for SARS-CoV-2 in recovered COVID-19 patients are suggested, including false-negative, false-positive RT-PCR tests; reactivation; and re-infection with SARS-CoV-2, but the mechanism leading to these re-positive cases is still unclear. The prevention of re-positive testing in discharged patients is a fundamental measure to control the spread of the pandemic. In order to reduce the percentage of false-negative tests prior to discharge, we recommend performing more than two tests, according to the standard sampling and microbiological assay protocol. In addition, specimens should be collected from multiple body parts if possible, to identify SARS-CoV-2 viral RNA before discharge. Further studies should be conducted to develop novel assays that target a crucial region of the RNA genome in order to improve its sensitivity and specificity.
Diagnosis of severe acute respiratory syndrome coronavirus 2 (SARS-COV-2) cases is based on the count of real-time reverse transcription-plymerase chain reaction (RT-PCR) positive people. Viral load by real-time RT-PCR has been suggested as a biomarker of the SARS-CoV-2 infection. However, the association of viral load and severity of the disease is not yet resolved. Nasopharyngeal samples from 458 patients were tested by RT-PCR for SARS-CoV-2 diagnosis. Relative quantitation was made by the comparative threshold cycle (ΔΔCt ) formula between ORF1ab viral and RNase P housekeeping genes. Absolute viral load was calculate using a reference positive control. Most prevalent clinical signs were cough (75.8%), myalgia (66.7%), and fever (48.5%). Hypertension (18.2%), neurological diseases (15.1%), and asthma and hypothyroidism (12.1%) were most frequent comorbidities. Fever, either as an exclusive symptom or combined with others, was associated with high viral loads ( 2−ΔΔCt range, 35.65-155.16; 4.25-4.89 log10 RNA copies/test]). During the first week after onset of symptoms in mild patients up to 60 years-old was detected the peak of viral load. Children under 10 years old have a high viral load (313.84; 2.50) in the first 2 days postinfection with a sharp decline thereafter. Cases between 10 and 49 years old mostly showed low and moderate viral load during the first 2 days postinfection (range, 0.03 to 17.24; -1.50 to 1.24). Patients over 60 years old have high viral load up to the second week after the onset of symptoms (range, 25.32-155.42; 1.40-2.19), indicating the longer presence of the virus in them. These findings suggest the viral load in nasopharyngeal swabs would help to monitor the SARS-CoV-2 infection in mild coronavirus disease 2019 cases.
Diagnosis of severe acute respiratory syndrome coronavirus 2 (SARS-COV-2) cases is based on the count of real-time reverse transcription-plymerase chain reaction (RT-PCR) positive people. Viral load by real-time RT-PCR has been suggested as a biomarker of the SARS-CoV-2 infection. However, the association of viral load and severity of the disease is not yet resolved. Nasopharyngeal samples from 458 patients were tested by RT-PCR for SARS-CoV-2 diagnosis. Relative quantitation was made by the comparative threshold cycle (ΔΔCt ) formula between ORF1ab viral and RNase P housekeeping genes. Absolute viral load was calculate using a reference positive control. Most prevalent clinical signs were cough (75.8%), myalgia (66.7%), and fever (48.5%). Hypertension (18.2%), neurological diseases (15.1%), and asthma and hypothyroidism (12.1%) were most frequent comorbidities. Fever, either as an exclusive symptom or combined with others, was associated with high viral loads ( 2−ΔΔCt range, 35.65-155.16; 4.25-4.89 log10 RNA copies/test]). During the first week after onset of symptoms in mild patients up to 60 years-old was detected the peak of viral load. Children under 10 years old have a high viral load (313.84; 2.50) in the first 2 days postinfection with a sharp decline thereafter. Cases between 10 and 49 years old mostly showed low and moderate viral load during the first 2 days postinfection (range, 0.03 to 17.24; -1.50 to 1.24). Patients over 60 years old have high viral load up to the second week after the onset of symptoms (range, 25.32-155.42; 1.40-2.19), indicating the longer presence of the virus in them. These findings suggest the viral load in nasopharyngeal swabs would help to monitor the SARS-CoV-2 infection in mild coronavirus disease 2019 cases.
Knowledge of the sensitivities of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) antibody tests beyond 35 days after the clinical onset of COVID-19 is insufficient. We aimed to describe positivity rate of SARS-CoV-2 assays employing three different measurement principles over a prolonged period. Two hundred sixty-eight samples from 180 symptomatic patients with COVID-19 and a reverse transcription polymerase chain reaction (RT-PCR) test followed by serological investigation of SARS-CoV-2 antibodies were included. We conducted three chemiluminescence (including electrochemiluminescence assay (ECLIA)), four enzyme-linked immunosorbent assay (ELISA), and one lateral flow immunoassay (LFIA) test formats. Positivity rates, as well as positive (PPVs) and negative predictive values (NPVs), were calculated for each week after the first clinical presentation for COVID-19. Furthermore, combinations of tests were assessed within an orthogonal testing approach employing two independent assays and predictive values were calculated. Heat maps were constructed to graphically illustrate operational test characteristics. During a follow-up period of more than 9 weeks, chemiluminescence assays and one ELISA IgG test showed stable positivity rates after the third week. With the exception of ECLIA, the PPVs of the other chemiluminescence assays were ≥95% for COVID-19 only after the second week. ELISA and LFIA had somewhat lower PPVs. IgM exhibited insufficient predictive characteristics. An orthogonal testing approach provided PPVs ≥ 95% for patients with a moderate pretest probability (e.g., symptomatic patients), even for tests with a low single test performance. After the second week, NPVs of all but IgM assays were ≥95% for patients with low to moderate pretest probability. The confirmation of negative results using an orthogonal algorithm with another assay provided lower NPVs than the single assays. When interpreting results from SARS-CoV-2 tests, the pretest probability, time of blood draw, and assay characteristics must be carefully considered. An orthogonal testing approach increases the accuracy of positive, but not negative, predictions.
The number of serological assays for SARS-CoV-2 has skyrocketed in the past year. Concerns have been raised regarding their performance characteristics, depending on the disease severity and the time of the analysis post-symptom onset (PSO). Thus, independent validations using an unbiased sample selection are required for meaningful serology data interpretation. We aimed to assess the clinical performance of six commercially available assays, the seroconversion, and the dynamics of the humoral response to SARS-CoV-2 infection. The study included 528 serum samples from 156 patients with follow-up visits up to six months PSO and 161 serum samples from healthy people. The IgG/total antibodies positive percentage increased and remained above 95% after six months when chemiluminescent immunoassay (CLIA) IgG antiS1/S2 and electro-chemiluminescent assay (ECLIA) total antiNP were used. At early time points PSO, chemiluminescent microparticle immunoassay (CMIA) IgM antiS achieved the best sensitivity. IgM and IgG appear simultaneously in most circumstances, and when performed in parallel the sensitivity increases. The severe and the moderate clinical forms were significantly associated with higher seropositivity percentage and antibody levels. High specificity was found in all evaluated assays, but the sensitivity was variable depending on the time PSO, severity of disease, detection method and targeted antigen.
This study aimed to monitor severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) viral loads and specific serum-antibodies (immunoglobulin [Ig] G and M) among confirmed patients and asymptomatic carriers from returning healthy travelers. The throat swabs, sputum, and stool samples from 57 hospitalized coronavirus disease (COVID-19) patients and 8 asymptomatic carriers, among 170 returning healthy travelers were tested using reverse-transcription real-time polymerase chain reaction. SARS-CoV-2 IgM/IgG antibodies were detected via serum chemiluminescence assay. Sequential results showed higher viral RNA loads in the throat, sputum, and stool samples at 3-12 and 6-21 days after symptom onset among severely ill COVID-19 patients. Shorter viral habitation time (1-8 days) was observed in the oropharyngeal site and intestinal tract of asymptomatic carriers. The IgG and IgM response rates were 19/37 (51.4%) and 23/37 (62.6%) among the 29 confirmed patients and 8 asymptomatic carriers, respectively, within 66 days from symptom or detection onset. The median duration between symptom onset and positive IgG and IgM results was 30 (n=23; interquartile range [IQR]=20-66) and 23 (n=19; IQR=12-28) days, respectively. Of 170 returning healthy-travelers to China, 4.7% were asymptomatic carriers (8/170) within 2 weeks, and the IgG and IgM positivity rate was 12.8% (12/94). IgM/IgG-positivity confirmed 3 suspected SARS-CoV-2 cases, despite negative results for SARS-CoV-2 RNA. Compared with other respiratory viral infectious diseases, COVID-19 has fewer asymptomatic carriers, lower antibody response rates, and a longer antibody production duration in recovered patients and the contacted healthy population. This is an indication of the complexity of COVID-19 transmission.
This study aimed to monitor severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) viral loads and specific serum-antibodies (immunoglobulin [Ig] G and M) among confirmed patients and asymptomatic carriers from returning healthy travelers. The throat swabs, sputum, and stool samples from 57 hospitalized coronavirus disease (COVID-19) patients and 8 asymptomatic carriers, among 170 returning healthy travelers were tested using reverse-transcription real-time polymerase chain reaction. SARS-CoV-2 IgM/IgG antibodies were detected via serum chemiluminescence assay. Sequential results showed higher viral RNA loads in the throat, sputum, and stool samples at 3-12 and 6-21 days after symptom onset among severely ill COVID-19 patients. Shorter viral habitation time (1-8 days) was observed in the oropharyngeal site and intestinal tract of asymptomatic carriers. The IgG and IgM response rates were 19/37 (51.4%) and 23/37 (62.6%) among the 29 confirmed patients and 8 asymptomatic carriers, respectively, within 66 days from symptom or detection onset. The median duration between symptom onset and positive IgG and IgM results was 30 (n=23; interquartile range [IQR]=20-66) and 23 (n=19; IQR=12-28) days, respectively. Of 170 returning healthy-travelers to China, 4.7% were asymptomatic carriers (8/170) within 2 weeks, and the IgG and IgM positivity rate was 12.8% (12/94). IgM/IgG-positivity confirmed 3 suspected SARS-CoV-2 cases, despite negative results for SARS-CoV-2 RNA. Compared with other respiratory viral infectious diseases, COVID-19 has fewer asymptomatic carriers, lower antibody response rates, and a longer antibody production duration in recovered patients and the contacted healthy population. This is an indication of the complexity of COVID-19 transmission.
The introduction of technologically advanced methods of lithotripsy into medical practice changes the nature of postoperative complications. Among them, the main complications are inflammatory infections. This largely determines the search for new, improved methods of stone fragmentation avoiding small stone fragments and dissemination of the pelvicalyceal system of the kidney with stone-associated infection. The authors have developed a method for controlled stone fragmentation using a continuous-wave diode laser with a hot-spot effect at the optical fiber end. The aim of the study was to evaluate the efficacy of controlled urinary stone fragmentation using a continuous-wave diode laser with a highly heated distal end of the optical fiber light guide as a method of preventing inflammatory infections in clinical practice. Materials and methods: We analyzed 1666 case histories of urolithiasis patients who underwent percutaneous nephrolithotripsy/ nephrolithoextraction and contact ureterolithotripsy/ureteroextraction, we also performed a prospective analysis of complications based on the Clavien-Dindo classification in 90 patients who underwent fine fragmentation of stones with various lithotripters: ultrasonic, pneumatic, and holmium laser. The method of controlled stone fragmentation by a diode laser with a hot-spot effect was tested on postoperative samples of 26 renal calculi. For the first time in clinical practice, this method was tested in the bladder cavity (n=10). Results: In the percutaneous nephrolithotripsy group, postoperative infectious and inflammatory complications occurred in 34.1% of cases, in the percutaneous nephrolithoextraction group - in 24.6%, in the contact ureterolithotripsy group - in 7.8%, in the ureterolithoextraction group - in 2.5%. The analysis made it possible to identify factors promoting the development of infectious and inflammatory complications. For the first time in clinical practice, there were successfully performed ten operations of stone fragmentation using a continuous-wave diode laser with a hot-spot effect. Controlled coarse fragmentation of stones providing the possibility to reduce the number of infectious and inflammatory complications was performed in the bladder as a model for testing the method. Conclusion: The method of laser-induced controlled coarse fragmentation of stones with a hot-spot effect, developed and tested in clinical practice, is promising for the prevention of infectious and inflammatory complications in patients with potentially infected stones since their fine fragmentation and, consequently, spread of stone-associated toxins and microflora within the urinary system is avoided.
The introduction of technologically advanced methods of lithotripsy into medical practice changes the nature of postoperative complications. Among them, the main complications are inflammatory infections. This largely determines the search for new, improved methods of stone fragmentation avoiding small stone fragments and dissemination of the pelvicalyceal system of the kidney with stone-associated infection. The authors have developed a method for controlled stone fragmentation using a continuous-wave diode laser with a hot-spot effect at the optical fiber end. The aim of the study was to evaluate the efficacy of controlled urinary stone fragmentation using a continuous-wave diode laser with a highly heated distal end of the optical fiber light guide as a method of preventing inflammatory infections in clinical practice. Materials and methods: We analyzed 1666 case histories of urolithiasis patients who underwent percutaneous nephrolithotripsy/ nephrolithoextraction and contact ureterolithotripsy/ureteroextraction, we also performed a prospective analysis of complications based on the Clavien-Dindo classification in 90 patients who underwent fine fragmentation of stones with various lithotripters: ultrasonic, pneumatic, and holmium laser. The method of controlled stone fragmentation by a diode laser with a hot-spot effect was tested on postoperative samples of 26 renal calculi. For the first time in clinical practice, this method was tested in the bladder cavity (n=10). Results: In the percutaneous nephrolithotripsy group, postoperative infectious and inflammatory complications occurred in 34.1% of cases, in the percutaneous nephrolithoextraction group - in 24.6%, in the contact ureterolithotripsy group - in 7.8%, in the ureterolithoextraction group - in 2.5%. The analysis made it possible to identify factors promoting the development of infectious and inflammatory complications. For the first time in clinical practice, there were successfully performed ten operations of stone fragmentation using a continuous-wave diode laser with a hot-spot effect. Controlled coarse fragmentation of stones providing the possibility to reduce the number of infectious and inflammatory complications was performed in the bladder as a model for testing the method. Conclusion: The method of laser-induced controlled coarse fragmentation of stones with a hot-spot effect, developed and tested in clinical practice, is promising for the prevention of infectious and inflammatory complications in patients with potentially infected stones since their fine fragmentation and, consequently, spread of stone-associated toxins and microflora within the urinary system is avoided.
Introduction: We determine the effect of patient characteristics (age, sex, and body mass index BMI) and stone characteristics (density, location, and size) by non-contrast computed tomography of the kidneys, ureters, and bladder (CT-KUB) in predicting the success of extracorporeal shock wave lithotripsy (ESWL) in the treatment of kidney and ureteric stones. We present this study to further enrich the knowledge of physicians towards the effect of different patient characteristics upon predicting extra-corporal shock wave lithotripsy success rates. Methods: We evaluated 155 patients who received ESWL for renal and ureteric stone measuring 3-20 mm (mm), over a 3-month period. The stone size in millimeters, density in Hounsfield units (HU) and its location was determined on pre-treatment CT-KUB. ESWL was successful if post-treatment residual renal stone fragments were ≤3 mm and for ureteric stones should be totally cleared. Results: The overall success of ESWL treatment was observed in 65.8% of the 155 patients. There was no significant difference seen when the effect of patients age, sex and BMI were studied with ESWL outcome with P values were 0.155, 0.101 and 0.415 respectively. Also, stone location either in the kidney or ureter has no statistically significant effect on ESWL response rate. while stone density and size determined on CT KUB have statistically significant effect on the success rate of ESWL with a P-value of 0.002 and 0.000 respectively. Conclusions: This study shows that determination of stone density and stone size on CT KUB pre ESWL can help to predict the outcome of ESWL. We propose that stone density <500 HU and stone size < 5 mm are highly likely to result in successful ESWL.
Introduction: Although spinal anesthesia (SA) may reduce postoperative morbidity, most urologists perform flexible ureterorenoscopy (fURS) under general anesthesia (GA). The objective of our study is to provide technical details, results, complications, and patients' satisfaction with fURS performed under exclusive SA. Methods: We analyzed all consecutive fURS performed under SA to treat renal stones from March 2011 to February 2017. Details of technique, operative time, outcomes, need for further treatments, complications, and patients' satisfaction were evaluated. Results: Two hundred thirty-four fURS under SA were considered. SA was performed through L2-L3 vertebral interspace in 64.1%. Patients were discharged the same day of surgery. Mean stone burden was 13.5 ± 6.6 mm and mean operative time 76.9 ± 34.6 min. Single-procedure SFR was 69.7%. Further treatments were performed in 22.8%. 96.6% had no anesthesia-related complications. No Clavien-Dindo grade ≥ IIIb complications were noticed. 99.6% of patients were satisfied with SA. No cases of conversion from SA to GA occurred. Conclusion: fURS can be performed safely and efficiently under SA, taking into account a few details of the technique. Patients' satisfaction with SA is very high, and complications are rare. Although SA is usually adopted in unfit patients for GA, it may be considered as a viable alternative in fit patients.
The mini percutaneous nephrolithotomy (mini-PCNL) has become a versatile tool to remove kidney stones >2 cm, lower pole stones >1 cm, renal stones previously unresponsive to shockwave therapy or inaccessible by ureteroscopy (within a caliceal diverticulum), stones within complex urinary tracts (urinary diversions, transplanted kidney, and horseshoe kidneys), and large impacted proximal ureteral stones. After positioning in either the supine or prone position, a cystoscopy is performed to place an open-ended catheter, occlusion balloon, or Accordian device into the collecting system. A foley catheter is placed in the bladder. An ultrasound with a curvilinear probe is used to survey the kidney and guide access into the collecting system with an 18 g percutaneous needle. Once access is obtained, a small 0.5 cm skin incision is made and the percutaneous tract is dilated over a wire. A 16.5F metallic or self-dilating suctioning access sheath is positioned with fluoroscopic guidance. A 12F rigid mini-PCNL nephroscope is used to evaluate the collecting system. Once a calculus is observed, options for stone fragmentation include a lithotripter with ultrasonic and ballistic energy, or laser lithotripsy using holmium or thulium laser fibers. Flexible ureteroscopy can be considered to ensure clearance of the collecting system. A 6F ureteral stent can be placed in either a retrograde or antegrade approach for drainage. The tract is sealed using Surgiflo hemostatic matrix with thrombin. Guidelines for postoperative care and troubleshooting techniques for mini-PCNL are reviewed along with the surgical steps in the accompanying video (Supplementary Video S1). There are few randomized trials comparing mini-PCNL with standard PCNL and ureteroscopy. There is some evidence to suggest a difference in transfusion rates comparing mini- and standard PCNL, as well as differences in stone-free rates when comparing mini-PCNL with ureteroscopy for the treatment of lower pole stones.
The mini percutaneous nephrolithotomy (mini-PCNL) has become a versatile tool to remove kidney stones >2 cm, lower pole stones >1 cm, renal stones previously unresponsive to shockwave therapy or inaccessible by ureteroscopy (within a caliceal diverticulum), stones within complex urinary tracts (urinary diversions, transplanted kidney, and horseshoe kidneys), and large impacted proximal ureteral stones. After positioning in either the supine or prone position, a cystoscopy is performed to place an open-ended catheter, occlusion balloon, or Accordian device into the collecting system. A foley catheter is placed in the bladder. An ultrasound with a curvilinear probe is used to survey the kidney and guide access into the collecting system with an 18 g percutaneous needle. Once access is obtained, a small 0.5 cm skin incision is made and the percutaneous tract is dilated over a wire. A 16.5F metallic or self-dilating suctioning access sheath is positioned with fluoroscopic guidance. A 12F rigid mini-PCNL nephroscope is used to evaluate the collecting system. Once a calculus is observed, options for stone fragmentation include a lithotripter with ultrasonic and ballistic energy, or laser lithotripsy using holmium or thulium laser fibers. Flexible ureteroscopy can be considered to ensure clearance of the collecting system. A 6F ureteral stent can be placed in either a retrograde or antegrade approach for drainage. The tract is sealed using Surgiflo hemostatic matrix with thrombin. Guidelines for postoperative care and troubleshooting techniques for mini-PCNL are reviewed along with the surgical steps in the accompanying video (Supplementary Video S1). There are few randomized trials comparing mini-PCNL with standard PCNL and ureteroscopy. There is some evidence to suggest a difference in transfusion rates comparing mini- and standard PCNL, as well as differences in stone-free rates when comparing mini-PCNL with ureteroscopy for the treatment of lower pole stones.
Background: This study aimed to assess the efficacy and safety of minimally invasive percutaneous nephrolithotomy (MPCNL) versus standard percutaneous nephrolithotomy in patients with renal and upper ureteric stones. Methods: We conducted a pooled analysis on randomized controlled trials (RCTs). The eligible RCTs were selected from the following databases: MEDLINE, Embase, Web of Science, and the Cochrane Library. The reference lists of retrieved studies were also investigated. Results: Our analysis included 10 RCTs with 1612 patients. Pooled data from 10 RCTs revealed the following: stone-free rate (odds ratio = 1.46, 95% confidence interval (CI) [1.12,1.88], P = .004), operative time (mean difference [MD] = 4.10, 95% CI [-1.37,9.56], P = .14), length of hospital stay (MD = -15.31, 95% CI [-29.43,-1.19], P = .03), hemoglobin decrease (MD = -0.86, 95% CI [-1.19,-0.53], P < .00001), postoperative fever (MD = 0.83, 95% CI [0.49,1.40], P = .49), and urine leakage (MD = 0.59, 95% CI [0.25,1.37], P = .22). Besides, we performed sub-group analysis based on vacuum suction effect and multiple kidney stones. For vacuum suction effect, it revealed the following: stone-free rate in vacuum suction group (P = .007) and in non-vacuum suction group (P = .19). Operative time in vacuum suction group (P = .89), non-vacuum suction group (P = .16). Postoperative fever in vacuum suction group (P = .49), non-vacuum suction group (P = .85). Conclusion: This pooled analysis indicated that MPCNL was a safe and effective method for treating renal stones compared with standard percutaneous nephrolithotomy. Besides, the vacuum suction effect in MPCNL played a more important role. When it comes to multiple or staghorn stones, the longer operative time in MPCNL could not be ignored.
Mini-Percutaneous Nephrolithotomy (M-PCNL) and Retrograde Intrarenal Surgery (RIRS) are commonly used methods in treatment of kidney stones. The aim of our study is to compare the efficacy and safety of M-PCNL and RIRS in kidney stone treatment over 50 years old patients. A total of 125 patients, 65 of whom had RIRS, and 60 of whom had M-PCNL, were included in the study. Age, gender, BMI (Body-Mass Index), ASA (American Society of Anesthesiology) scores of the patients; stone size, stone location, operation side, ESWL history, HU (Hounsfield Unit) values, hospital stay durations, SFR, complication rates according to Clavien modification system, postoperative hemoglobin loss, postoperative transfusion rates, and patients who needed a secondary operation were recorded. SFR values were calculated in the postoperative third and sixth months. The data between the two groups had similar characteristics in terms of age, gender, BMI, HU, stone size, operation side, stone location, ESWL history, operation time, postoperative transfusion rate, postoperative Clavien complications (p > 0.05). When the ASA categories were evaluated, the mean ASA scores, ASA I, and ASA II data had similar characteristics in both groups (p > 0.05). When the ASA 3 scores were evaluated, the number of ASA III patients in the RIRS group was statistically significantly higher (p < 0.05). When hospital stay duration and postoperative hemoglobin loss were examined, RIRS group was found to be advantageous (p < 0.05). Postoperative third month SFR and Postoperative sixth month values were statistically significantly higher in M-PCNL group (p < 0.05). M-PCNL and RIRS are methods that can be used safely and effectively over 50 years old patients in kidney stone surgery. M-PCNL has been found to be more advantageous in terms of SFR rates and as it requires less secondary intervention. RIRS is advantageous in terms of short hospital stay, postoperative hemoglobin loss, and applicability to patients who are not suitable for the prone position.
Renal stones pose a significant burden on the health care system. The prevalence of renal stones has increased from 3.8% in 1970 to 8.8% in 2010 in the United States, with annual healthcare costs of USD 3.8 billion. It is estimated that more than half a million people a year visit the emergency room for kidney stone problems. The most common presenting symptoms include hematuria, pain in the flank, groin, or abdomen. There are many treatment modalities available for managing renal stones. They range from completely non-invasive outpatient procedures to invasive procedures requiring hospital admission and increased risks of complications. Extracorporeal shockwave lithotripsy (ESWL) is a truly non-invasive procedure as opposed to other surgical treatments used, such as retrograde intrarenal surgery (RIRS) and percutaneous nephrolithotomy (PCNL). The efficacy of ESWL lies in its ability to pulverize calculi in vivo into smaller segments, which are them expelled spontaneously by the boy. Shockwaves are generated and are then focused on a point within the body. The shockwaves propagate through the body with minimal dissipation of energy (and therefore damage) due to minimal difference in density of the soft tissues. At the stone fluid interface, a relatively significant difference in density, combined with a large concentration of multiple shockwaves in a small area, produces a significant dissipation of energy. Through the different mechanisms, this energy can overcome the tensile strength of the stone resulting in fragmentation. Repetition of this process leads to the pulverization of the stone into small fragments that the body then can pass painlessly and spontaneously.
Renal stones pose a significant burden on the health care system. The prevalence of renal stones has increased from 3.8% in 1970 to 8.8% in 2010 in the United States, with annual healthcare costs of USD 3.8 billion. It is estimated that more than half a million people a year visit the emergency room for kidney stone problems. The most common presenting symptoms include hematuria, pain in the flank, groin, or abdomen. There are many treatment modalities available for managing renal stones. They range from completely non-invasive outpatient procedures to invasive procedures requiring hospital admission and increased risks of complications. Extracorporeal shockwave lithotripsy (ESWL) is a truly non-invasive procedure as opposed to other surgical treatments used, such as retrograde intrarenal surgery (RIRS) and percutaneous nephrolithotomy (PCNL). The efficacy of ESWL lies in its ability to pulverize calculi in vivo into smaller segments, which are them expelled spontaneously by the boy. Shockwaves are generated and are then focused on a point within the body. The shockwaves propagate through the body with minimal dissipation of energy (and therefore damage) due to minimal difference in density of the soft tissues. At the stone fluid interface, a relatively significant difference in density, combined with a large concentration of multiple shockwaves in a small area, produces a significant dissipation of energy. Through the different mechanisms, this energy can overcome the tensile strength of the stone resulting in fragmentation. Repetition of this process leads to the pulverization of the stone into small fragments that the body then can pass painlessly and spontaneously.
Background Percutaneous nephrolithotomy (PCNL) is the first choice treatment of renal stones larger than 2 cm. We aimed to evaluate if lasers perform as equal as non-laser devices in patients with kidney stones candidate to PCNL. Materials and methods A comprehensive literature search was performed in MEDLINE via PubMed, Scopus and Cochrane Central Register of Controlled Trials (CENTRAL) to assess the differences in the perioperative course, incidence of postoperative complications, and stone free-rate (SFR) in patients with kidney stones undergoing laser versus non-laser PCNL in randomized studies. The incidences of complications were pooled using the Cochran-Mantel-Haenszel Method with the random effect model and expressed as Risk Ratios (RR), 95% Confidence Intervals (CI), and p-values. Surgical time and length of stay were pooled using the inverse variance of the mean difference (MD) with a random effect, 95% CI, and p-values. Analyses were two-tailed, with a significance set at p ≤0.05. Results Six papers including 732 patients (311 patients undergoing holmium laser and 421 non-laser PCNL) were included in meta-analysis. Surgical time and postoperative stay were shorter in the non-laser group (MD:11.14, 95% CI:2.32-19.96, p=0.002; MD:-0.81, 95%CI:-2.18-0.57 p=0.25, respectively). SFR was significantly higher in the non-laser group (RR:1.08, 95% CI:1.01-1.15, p=0.03). Patients undergoing laser PCNL had a non-significant higher risk of postoperative fever >38°C (RR:0.64, 95%CI: .31-1.30, p=0.22). Transfusion rate did not differ between the two groups (RR:1.02, 95% CI:0.50-2.11 p=0.95). The need for stent positioning due to urine extravasation was higher risk in the laser group but the difference did not reach significance (RR:0.49, 95% CI:0.17-1.41 p=0.19). Conclusions Non-laser PCNL showed better perioperative outcomes and SFR as compared to holmium laser PCNL.
The primary goals of medical expulsive therapy are to increase the rate of stone expulsion along the ureter to avoid ureteral obstruction and reduce ureteral colic and thus avoid the need for surgical and more invasive interventions. This review focussed on the findings from in vivo and in vitro animal and human studies that have investigated the pharmacological mechanisms controlling ureteral motility and their translation to current and potentially new clinically used drugs for increasing the rate of stone expulsion along the ureter. The complicated contractility profile of the ureter, which alters with age, tissue segment region, orientation and species contributes to the difficulty of interpreting studies on ureteral pharmacology, which translates to the complexity of discovering ideal drug targets for medical expulsive therapy. Nevertheless, the current drug classes clinically used for patients with stone lodgement include α1 -adrenoceptor antagonists, calcium channel blockers and NSAIDS, whilst there are promising targets for drug development that require further clinical investigations including the phosphodiesterase type 5 enzyme, β-adrenoceptors and 5-HT receptors.
The landscape of managing ureteric stones has evolved over the last few decades and several treatment options exist depending on the stone size, location, and other patient and stone factors. While open surgery is now rarely performed, the use of medical expulsive therapy (MET) has been controversial and perhaps only recommended for large distal ureteric stones. The mainstay treatment balances between shockwave lithotripsy (SWL) and ureteroscopy (URS), with the latter usually recommended for larger stones. While the principles of ureteric stone management have remained largely unchanged, the modern era has generated new methods and means to deliver it. Advancements have occurred in all domains of endourology to try and refine treatment and balance it with cost, patient choice and quality of life. Dissemination of technologies and demonstration of their efficacy and safety will eventually result in new recommendations among international guidelines and evolution of new gold standards.
The landscape of managing ureteric stones has evolved over the last few decades and several treatment options exist depending on the stone size, location, and other patient and stone factors. While open surgery is now rarely performed, the use of medical expulsive therapy (MET) has been controversial and perhaps only recommended for large distal ureteric stones. The mainstay treatment balances between shockwave lithotripsy (SWL) and ureteroscopy (URS), with the latter usually recommended for larger stones. While the principles of ureteric stone management have remained largely unchanged, the modern era has generated new methods and means to deliver it. Advancements have occurred in all domains of endourology to try and refine treatment and balance it with cost, patient choice and quality of life. Dissemination of technologies and demonstration of their efficacy and safety will eventually result in new recommendations among international guidelines and evolution of new gold standards.
Eight types of short-chain Lys acylations have recently been identified on histones: propionylation, butyrylation, 2-hydroxyisobutyrylation, succinylation, malonylation, glutarylation, crotonylation and β-hydroxybutyrylation. Emerging evidence suggests that these histone modifications affect gene expression and are structurally and functionally different from the widely studied histone Lys acetylation. In this Review, we discuss the regulation of non-acetyl histone acylation by enzymatic and metabolic mechanisms, the acylation 'reader' proteins that mediate the effects of different acylations and their physiological functions, which include signal-dependent gene activation, spermatogenesis, tissue injury and metabolic stress. We propose a model to explain our present understanding of how differential histone acylation is regulated by the metabolism of the different acyl-CoA forms, which in turn modulates the regulation of gene expression.
Over time, the knowledge on the role of histones has significantly changed. Initially, histones were only known as DNA packaging proteins but later, it was discovered that they act extracellularly as powerful antimicrobial agents and also as potentially self-detrimental agents. Indeed, histones were found to be the most abundant proteins within neutrophil extracellular traps what ultimately highlighted their microbicidal function. In addition, extracellular histones proved to be involved in triggering exacerbated inflammatory and coagulation responses, depending on the cell type affected. Consequently, several investigations were conducted towards studying the potential of histones and their derivatives as either biomarkers or therapeutic target candidates in different diseases in which inflammation and thrombosis have a key pathophysiological role, such as sepsis, thrombosis and different types of cancer. The main objective of this review is to summarize and discuss the current state of the art with regard to both beneficial and harmful roles of histones and also their possible use as biomarkers and therapeutic targets.
Histones are known for their ability to bind to and regulate expression of DNA. However, histones are also present in cytoplasm and extracellular fluids where they serve host defense functions and promote inflammatory responses. Histones are a major component of neutrophil extracellular traps that contribute to bacterial killing but also to inflammatory injury. Histones can act as antimicrobial peptides and directly kill bacteria, fungi, parasites and viruses, in vitro and in a variety of animal hosts. In addition, histones can trigger inflammatory responses in some cases acting through Toll-like receptors or inflammasome pathways. Extracellular histones mediate organ injury (lung, liver), sepsis physiology, thrombocytopenia and thrombin generation and some proteins can bind histones and reduce these potentially harmful effects
Histones are known for their ability to bind to and regulate expression of DNA. However, histones are also present in cytoplasm and extracellular fluids where they serve host defense functions and promote inflammatory responses. Histones are a major component of neutrophil extracellular traps that contribute to bacterial killing but also to inflammatory injury. Histones can act as antimicrobial peptides and directly kill bacteria, fungi, parasites and viruses, in vitro and in a variety of animal hosts. In addition, histones can trigger inflammatory responses in some cases acting through Toll-like receptors or inflammasome pathways. Extracellular histones mediate organ injury (lung, liver), sepsis physiology, thrombocytopenia and thrombin generation and some proteins can bind histones and reduce these potentially harmful effects
Background: The oncogenic role of histone mutations is one of the most relevant discovery in cancer epigenetics. Recurrent mutations targeting histone genes have been described in pediatric brain tumors, chondroblastoma, giant cell tumor of bone and other tumor types. The demonstration that mutant histones can be oncogenic and drive the tumorigenesis in pediatric tumors, led to the coining of the term "oncohistones." The first identified histone mutations were localized at or near residues normally targeted by post-translational modifications (PTMs) in the histone N-terminal tails and suggested a possible interference with histone PTMs regulation and reading. Main body: In this review, we describe the peculiar organization of the multiple genes that encode histone proteins, and the latter advances in both the identification and the biological role of histone mutations in cancer. Recent works show that recurrent somatic mutations target both N-terminal tails and globular histone fold domain in diverse tumor types. Oncohistones are often dominant-negative and occur at higher frequencies in tumors affecting children and adolescents. Notably, in many cases the mutations target selectively only some of the genes coding the same histone protein and are frequently associated with specific tumor types or, as documented for histone variant H3.3 in pediatric glioma, with peculiar tumors arising from specific anatomic locations. Conclusion: The overview of the most recent advances suggests that the oncogenic potential of histone mutations can be exerted, together with the alteration of histone PTMs, through the destabilization of nucleosome and DNA-nucleosome interactions, as well as through the disruption of higher-order chromatin structure. However, further studies are necessary to fully elucidate the mechanism of action of oncohistones, as well as to evaluate their possible application to cancer classification, prognosis and to the identification of new therapies.
Extracellular histones released from injured or dying cells following trauma and other severe insults can act as potent damage-associated molecular patterns. In fact, elevated levels of histones are present in human circulation in hyperinflammatory states such as acute respiratory distress syndrome and sepsis. The molecular mechanisms owing to histone-induced pathologies are at the very beginning of elucidating. However, neutralization of histones with antibodies, histone-binding or histone-degrading proteins, and heparan sulfates have shown promising therapeutic effects in pre-clinical acute respiratory distress syndrome and sepsis models. Various cell types undergoing necrosis and apoptosis or activated neutrophils forming neutrophil extracellular traps have been implicated in excessive release of histones which further augments tissue injury and may culminate in multiple organ failure. At the molecular level, an uncontrolled inflammatory cascade has been considered as the major event; however, histone-activated coagulation and thrombosis represent additional pathologic events reflecting coagulopathy. Furthermore, epigenetic regulation and chemical modifications of circulating histones appear to be critically important in their biological functions as evidenced by increased cytotoxicity associated with citrullinated histone. Herein, we will briefly review the current knowledge on the role of histones in acute respiratory distress syndrome and sepsis, and discuss the future potential of anti-histone therapy for treatment of these life-threatening disorders.
Linker histones are major players in chromatin organization and per se are essential players in genome homeostasis. As the fifth class of histone proteins the linker histones not only interact with DNA and core histones but also with other chromatin proteins. These interactions prove to be essential for the higher levels of chromatin organization like chromatin loops, transcription factories and chromosome territories. Our recent results have proved that Saccharomyces cerevisiae linker histone - Hho1p, physically interacts with the actin-related protein 4 (Arp4) and that the abrogation of this interaction through the deletion of the gene for the linker histone in arp4 mutant cells leads to global changes in chromatin compaction. Here, we show that the healthy interaction between the yeast linker histone and Arp4p is critical for maintaining genome stability and for controlling cellular sensitivity to different types of stress. The abolished interaction between the linker histone and Arp4p leads the mutant yeast cells to premature ageing phenotypes. Cells die young and are more sensitive to stress. These results unambiguously prove the role of linker histones and chromatin remodelling in ageing by their cooperation in pertaining higher-order chromatin compaction and thus maintaining genome stability.
Linker histones are major players in chromatin organization and per se are essential players in genome homeostasis. As the fifth class of histone proteins the linker histones not only interact with DNA and core histones but also with other chromatin proteins. These interactions prove to be essential for the higher levels of chromatin organization like chromatin loops, transcription factories and chromosome territories. Our recent results have proved that Saccharomyces cerevisiae linker histone - Hho1p, physically interacts with the actin-related protein 4 (Arp4) and that the abrogation of this interaction through the deletion of the gene for the linker histone in arp4 mutant cells leads to global changes in chromatin compaction. Here, we show that the healthy interaction between the yeast linker histone and Arp4p is critical for maintaining genome stability and for controlling cellular sensitivity to different types of stress. The abolished interaction between the linker histone and Arp4p leads the mutant yeast cells to premature ageing phenotypes. Cells die young and are more sensitive to stress. These results unambiguously prove the role of linker histones and chromatin remodelling in ageing by their cooperation in pertaining higher-order chromatin compaction and thus maintaining genome stability.
The linker histones (H1, H1 zero, H5, etc.) and a group of abundant non-histone chromosomal proteins (HMG1/2) bind to linker DNA in chromatin and exhibit both generalized and specific effects on gene transcription. The two classes of proteins share many features of DNA binding behaviour, although they are structurally unrelated. While the linker histones and HMG1/2 exhibit direct competition in binding to such structures as four-way junction DNA, whether they compete for binding to the nucleosome has not been investigated. The possibility for either opposite or synergistic effects on gene regulation must be considered at this point.
Histones constitute the chief protein component of DNA. They help to maintain chromatin structure and regulate gene expression. The long double-stranded DNA molecule winds around histone octamers to form nucleosomes which serve the purpose of compacting DNA within the confines of the nuclear membrane. There are five major types of histones, namely H1/H5, H2, H3 and H4. H3.3 is a subtype of H3 histone and can be encoded either by the H3F3A or H3F3B genes independently. Amino acids such as lysine and arginine found in the histone tails are sites of post-translational modifications (PTMs) such as methylation and acetylation. These PTMs in histones are involved in the regulation of gene expression by chromatin remodelling and by controlling DNA methylation patterns. Mutations in histone genes can affect sites of PTMs causing changes in local and global DNA methylation status. These effects are directly linked to neoplastic transformation by altered gene expression. Recurrent H3.3 histone mutations are increasingly identified in several malignancies and developmental disorders. The following review attempts to shed light on the diseases associated with H3.3 histone mutations.
cHistone posttranslational modifications (PTMs) are essential for regulating chromatin and maintaining gene expression throughout cell differentiation. Despite the deep level of understanding of immunophenotypic differentiation pathways in hematopoietic cells, few studies have investigated global levels of histone PTMs required for differentiation and maintenance of these distinct cell types. Here, we describe an approach to couple fluorescence-activated cell sorting (FACS) with targeted mass spectrometry to define global "epi-proteomic" signatures for primary leukocytes. FACS was used to sort closely and distantly related leukocytes from normal human peripheral blood for quantitation of histone PTMs with a multiple reaction monitoring LC-MS/MS method measuring histone PTMs on histones H3 and H4. We validate cell sorting directly into H2SO4 for immediate histone extraction to decrease time and number of steps after FACS to analyze histone PTMs. Relative histone PTM levels vary in T cells across healthy donors, and the majority of PTMs remain stable up to 2 days following initial blood draw. Large differences in the levels of histone PTMs are observed across the mature lymphoid and myeloid lineages, as well as between different types within the same lineage, though no differences are observed in closely related T cell subtypes. The results show a streamlined approach for quantifying global changes in histone PTMs in cell types separated by FACS that is poised for clinical deployment.
Background: While the genomes of eukaryotes and Archaea both encode the histone-fold domain, only eukaryotes encode the core histone paralogs H2A, H2B, H3, and H4. With DNA, these core histones assemble into the nucleosomal octamer underlying eukaryotic chromatin. Importantly, core histones for H2A and H3 are maintained as neofunctionalized paralogs adapted for general bulk chromatin (canonical H2 and H3) or specialized chromatin (H2A. Z enriched at gene promoters and cenH3s enriched at centromeres). In this context, the identification of core histone-like "doublets" in the cytoplasmic replication factories of the Marseilleviridae (MV) is a novel finding with possible relevance to understanding the origin of eukaryotic chromatin. Here, we analyze and compare the core histone doublet genes from all known MV genomes as well as other MV genes relevant to the origin of the eukaryotic replisome. Results: Using different phylogenetic approaches, we show that MV histone domains encode obligate H2B-H2A and H4-H3 dimers of possible proto-eukaryotic origin. MV core histone moieties form sister clades to each of the four eukaryotic clades of canonical and variant core histones. This suggests that MV core histone moieties diverged prior to eukaryotic neofunctionalizations associated with paired linear chromosomes and variant histone octamer assembly. We also show that MV genomes encode a proto-eukaryotic DNA topoisomerase II enzyme that forms a sister clade to eukaryotes. This is a relevant finding given that DNA topo II influences histone deposition and chromatin compaction and is the second most abundant nuclear protein after histones. Conclusions: The combined domain architecture and phylogenomic analyses presented here suggest that a primitive origin for MV histone genes is a more parsimonious explanation than horizontal gene transfers + gene fusions + sufficient divergence to eliminate relatedness to eukaryotic neofunctionalizations within the H2A and H3 clades without loss of relatedness to each of the four core histone clades. We thus suggest MV histone doublet genes and their DNA topo II gene possibly were acquired from an organism with a chromatinized replisome that diverged prior to the origin of eukaryotic core histone variants for H2/H2A.Z and H3/cen H3. These results also imply that core histones were utilized ancestrally in viral DNA compaction and/or protection from host endonucleases.
Background: While the genomes of eukaryotes and Archaea both encode the histone-fold domain, only eukaryotes encode the core histone paralogs H2A, H2B, H3, and H4. With DNA, these core histones assemble into the nucleosomal octamer underlying eukaryotic chromatin. Importantly, core histones for H2A and H3 are maintained as neofunctionalized paralogs adapted for general bulk chromatin (canonical H2 and H3) or specialized chromatin (H2A. Z enriched at gene promoters and cenH3s enriched at centromeres). In this context, the identification of core histone-like "doublets" in the cytoplasmic replication factories of the Marseilleviridae (MV) is a novel finding with possible relevance to understanding the origin of eukaryotic chromatin. Here, we analyze and compare the core histone doublet genes from all known MV genomes as well as other MV genes relevant to the origin of the eukaryotic replisome. Results: Using different phylogenetic approaches, we show that MV histone domains encode obligate H2B-H2A and H4-H3 dimers of possible proto-eukaryotic origin. MV core histone moieties form sister clades to each of the four eukaryotic clades of canonical and variant core histones. This suggests that MV core histone moieties diverged prior to eukaryotic neofunctionalizations associated with paired linear chromosomes and variant histone octamer assembly. We also show that MV genomes encode a proto-eukaryotic DNA topoisomerase II enzyme that forms a sister clade to eukaryotes. This is a relevant finding given that DNA topo II influences histone deposition and chromatin compaction and is the second most abundant nuclear protein after histones. Conclusions: The combined domain architecture and phylogenomic analyses presented here suggest that a primitive origin for MV histone genes is a more parsimonious explanation than horizontal gene transfers + gene fusions + sufficient divergence to eliminate relatedness to eukaryotic neofunctionalizations within the H2A and H3 clades without loss of relatedness to each of the four core histone clades. We thus suggest MV histone doublet genes and their DNA topo II gene possibly were acquired from an organism with a chromatinized replisome that diverged prior to the origin of eukaryotic core histone variants for H2/H2A.Z and H3/cen H3. These results also imply that core histones were utilized ancestrally in viral DNA compaction and/or protection from host endonucleases.
Therapeutic success in treating patients with systemic lupus erythematosus (SLE) is limited by the multivariate disease etiology, multi-organ presentation, systemic involvement, and complex immunopathogenesis. Agents targeting B-cell differentiation and survival are not efficacious for all patients, indicating a need to target other inflammatory mediators. One such target is the type I interferon pathway. Type I interferons upregulate interferon gene signatures and mediate critical antiviral responses. Dysregulated type I interferon signaling is detectable in many patients with SLE and other autoimmune diseases, and the extent of this dysregulation is associated with disease severity, making type I interferons therapeutically tangible targets. The recent approval of the type I interferon-blocking antibody, anifrolumab, by the US Food and Drug Administration for the treatment of patients with SLE demonstrates the value of targeting this pathway. Nevertheless, the interferon pathway has pleiotropic biology, with multiple cellular targets and signaling components that are incompletely understood. Deconvoluting the complexity of the type I interferon pathway and its intersection with lupus disease pathology will be valuable for further development of targeted SLE therapeutics. This review summarizes the immune mediators of the interferon pathway, its association with disease pathogenesis, and therapeutic modalities targeting the dysregulated interferon pathway.
Therapeutic success in treating patients with systemic lupus erythematosus (SLE) is limited by the multivariate disease etiology, multi-organ presentation, systemic involvement, and complex immunopathogenesis. Agents targeting B-cell differentiation and survival are not efficacious for all patients, indicating a need to target other inflammatory mediators. One such target is the type I interferon pathway. Type I interferons upregulate interferon gene signatures and mediate critical antiviral responses. Dysregulated type I interferon signaling is detectable in many patients with SLE and other autoimmune diseases, and the extent of this dysregulation is associated with disease severity, making type I interferons therapeutically tangible targets. The recent approval of the type I interferon-blocking antibody, anifrolumab, by the US Food and Drug Administration for the treatment of patients with SLE demonstrates the value of targeting this pathway. Nevertheless, the interferon pathway has pleiotropic biology, with multiple cellular targets and signaling components that are incompletely understood. Deconvoluting the complexity of the type I interferon pathway and its intersection with lupus disease pathology will be valuable for further development of targeted SLE therapeutics. This review summarizes the immune mediators of the interferon pathway, its association with disease pathogenesis, and therapeutic modalities targeting the dysregulated interferon pathway.
As treatment options in advanced systematic lupus erythematosus (SLE) are limited, there is an urgent need for new and effective therapeutic alternatives for selected cases with severe disease. Bortezomib (BTZ) is a specific, reversible, inhibitor of the 20S subunit of the proteasome. Herein, we report clinical experience regarding efficacy and safety from all patients receiving BTZ as therapy for SLE in Sweden during the years 2014-2020. 8 females and 4 males were included with a mean disease duration at BTZ initiation of 8.8 years (range 0.7-20 years). Renal involvement was the main target for BTZ. Reduction of global disease activity was recorded by decreasing SLEDAI-2K scores over time and remained significantly reduced at the 6-month (p=0.007) and the 12-month (p=0.008) follow-up visits. From BTZ initiation, complement protein 3 (C3) levels increased significantly after the 2nd treatment cycle (p=0.05), the 6-month (p=0.03) and the 12-month (p=0.04) follow-up visits. The urine albumin/creatinine ratio declined over time and reached significance at the 6-month (p=0.008) and the 12-month follow-up visits (p=0.004). Seroconversion of anti-dsDNA (27%), anti-C1q (50%) and anti-Sm (67%) was observed. 6 of 12 patients experienced at least one side-effect during follow-up, whereof the most common adverse events were infections. Safety parameters (C-reactive protein, blood cell counts) mainly remained stable over time. To conclude, we report favorable therapeutic effects of BTZ used in combination with corticosteroids in a majority of patients with severe SLE manifestations irresponsive to conventional immunosuppressive agents. Reduction of proteinuria was observed over time as well as seroconversion of some autoantibody specificities. In most patients, tolerance was acceptable but mild adverse events was not uncommon. Special attention should be paid to infections and hypogammaglobinemia.
Systemic lupus erythematosus (SLE) is a chronic autoimmune disease. Although previous studies have demonstrated that SLE is related to the imbalance of cells in the immune system, including B cells, T cells, and dendritic cells, etc., the mechanisms underlying SLE pathogenesis remain unclear. Therefore, effective and low side-effect therapies for SLE are lacking. Recently, mesenchymal stem cell (MSC) therapy for autoimmune diseases, particularly SLE, has gained increasing attention. This therapy can improve the signs and symptoms of refractory SLE by promoting the proliferation of Th2 and Treg cells and inhibiting the activity of Th1, Th17, and B cells, etc. However, MSC therapy is also reported ineffective in some patients with SLE, which may be related to MSC- or patient-derived factors. Therefore, the therapeutic effects of MSCs should be further confirmed. This review summarizes the status of MSC therapy in refractory SLE treatment and potential reasons for the ineffectiveness of MSC therapy from three perspectives. We propose various MSC modification methods that may be beneficial in enhancing the immunosuppression of MSCs in SLE. However, their safety and protective effects in patients with SLE still need to be confirmed by further experimental and clinical evidence.
Significance: Metformin has been proposed as a treatment for systemic lupus erythematosus (SLE). The primary target of metformin, the electron transport chain complex I in the mitochondria, is associated with redox homeostasis in immune cells, which plays a critical role in the pathogenesis of autoimmune diseases. This review addresses the evidence and knowledge gaps on whether a beneficial effect of metformin in lupus may be due to a restoration of a balanced redox state. Recent Advances: Clinical trials in SLE patients with mild to moderate disease activity and preclinical studies in mice have provided encouraging results for metformin. The mechanism by which this therapeutic effect was achieved is largely unknown. Metformin regulates redox homeostasis in a context-specific manner. Multiple cell types contribute to SLE, with evidence of increased mitochondrial oxidative stress in T cells and neutrophils. Critical issues: The major knowledge gaps are whether the efficacy of metformin is linked to a restored redox homeostasis in the immune system, and if it does, in which cell types it occurs? We also need to know which patients may have a better response to metformin, and whether it corresponds to a specific mechanism? Finally, the identification of biomarkers to predict treatment outcomes would be of great value.
Significance: Metformin has been proposed as a treatment for systemic lupus erythematosus (SLE). The primary target of metformin, the electron transport chain complex I in the mitochondria, is associated with redox homeostasis in immune cells, which plays a critical role in the pathogenesis of autoimmune diseases. This review addresses the evidence and knowledge gaps on whether a beneficial effect of metformin in lupus may be due to a restoration of a balanced redox state. Recent Advances: Clinical trials in SLE patients with mild to moderate disease activity and preclinical studies in mice have provided encouraging results for metformin. The mechanism by which this therapeutic effect was achieved is largely unknown. Metformin regulates redox homeostasis in a context-specific manner. Multiple cell types contribute to SLE, with evidence of increased mitochondrial oxidative stress in T cells and neutrophils. Critical issues: The major knowledge gaps are whether the efficacy of metformin is linked to a restored redox homeostasis in the immune system, and if it does, in which cell types it occurs? We also need to know which patients may have a better response to metformin, and whether it corresponds to a specific mechanism? Finally, the identification of biomarkers to predict treatment outcomes would be of great value.
Introduction: Low-dose interleukin-2 (IL-2) selectively restores disturbances of regulatory T cells (Treg) and conventional T cells, resulting in the induction of remission in patients with systemic lupus erythematosus. However, to date no research has been carried out on the efficacy of low-dose IL-2 in the treatment of refractory lupus nephritis (LN). The aim of the study reported here was to investigate the renal response to low-dose IL-2 in patients with refractory LN. Methods: The study population comprised ten patients with refractory LN who failed to achieve complete response or who had relapsed while being treated with at least two conventional immunosuppressive agents. One treatment cycle consisted of IL-2 at a dose of 1 million IU administered subcutaneously every other day for 2 weeks followed by a 2-week break. All patients received three cycles of IL-2 and were then followed up for another 12 weeks without any increase in the dose of previous immunosuppressive agents and steroids. Results: Of the ten patients enrolled in the study, seven (70%) achieved ≥ 50% improvement in proteinuria at 12 weeks after initiating treatment with IL-2. Median proteinuria was significantly reduced by 50.3% at week 12, from 1.83 (interquartile range [IQR] 1.23-3.21) g/24 h at baseline to 0.91 (IQR 0.52-1.60) g/24 h at 12 weeks (P = 0.005). This was accompanied by a 71% reduction in urine erythrocytes, from 64/µl (IQR 24-102/µl) at baseline to 18/µl (IQR 2-20/µl) at 12 weeks (P = 0.018). Anti-ds DNA was decreased from 27.9 (IQR 7.6-40.28) IU/ml at baseline to 14.1 (IQR 7.3-20.12) IU/ml (P = 0.021) at week 12, while complements C3 and C4 were slightly increased (P = 0.445, P = 0.241, respectively). A significant expansion of Treg cells, from 9.3% at baseline to 16.6% at 12 weeks, was also found (P < 0.05). No serious adverse events occurred during the treatment period. Conclusions: Low-dose IL-2 therapy may have a promising role in the treatment of refractory LN as an alternative and safe therapeutic approach. It may be used as multi-target combination therapy in clinical practice.
Objective: Randomised trials of type I anti-CD20 antibodies rituximab and ocrelizumab failed to show benefit in proliferative lupus nephritis (LN). We compared obinutuzumab, a humanised type II anti-CD20 monoclonal antibody that induces potent B-cell depletion, with placebo for the treatment of LN in combination with standard therapies. Methods: Patients with LN receiving mycophenolate and corticosteroids were randomised to obinutuzumab 1000 mg or placebo on day 1 and weeks 2, 24 and 26, and followed through week 104. The primary endpoint was complete renal response (CRR) at week 52. Exploratory analyses through week 104 were conducted. The prespecified alpha level was 0.2. Results: A total of 125 patients were randomised and received blinded infusions. Achievement of CRR was greater with obinutuzumab at week 52 (primary endpoint, 22 (35%) vs 14 (23%) with placebo; percentage difference, 12% (95% CI -3.4% to 28%), p=0.115) and at week 104 (26 (41%) vs 14 (23%); percentage difference, 19% (95% CI 2.7% to 35%), p=0.026). Improvements in other renal response measures, serologies, estimated glomerular filtration rate and proteinuria were greater with obinutuzumab. Obinutuzumab was not associated with increases in serious adverse events, serious infections or deaths. Non-serious infusion-related reactions occurred more frequently with obinutuzumab. Conclusions: Improved renal responses through week 104 were observed in patients with LN who received obinutuzumab plus standard therapies compared with standard therapies alone. Obinutuzumab was well tolerated and no new safety signals were identified.
Objective: To determine the relative effectiveness and safety of belimumab and anifrolumab in patients with active systemic lupus erythematosus (SLE). Materials and methods: A Bayesian network meta-analysis was performed from randomized controlled trials (RCTs) on the effectiveness and safety of belimumab 10 mg, anifrolumab 300 mg, and a placebo in patients with active SLE. Results: Six RCTs (2,757 patients) were included in this study. The response rate based on the SLE 4 Responder Index (SRI4) at 52 weeks was substantially higher in the belimumab 10-mg and anifrolumab 300-mg groups than that in the placebo group (OR 2.90, % credible intervals (CrIs) 2.37 - 3.56; OR 1.60, % CrI 1.22 - 2.08). The SRI4 response rate for belimumab 10 mg was significantly higher than that for anifrolumab 300 mg (OR 1.82, 95% CrI 1.30 - 2.53). Ranking probability based on surface under the cumulative ranking curve (SUCRA) indicated that belimumab 10 mg was most likely the best treatment for SRI4 response (SUCRA = 0.999), followed by anifrolumab 300 mg (SUCRA = 0.500) and placebo (SUCRA = 0.001). The number of serious adverse events (SAEs) did not differ significantly among the 4 treatment groups. Conclusion: Based on the SRI4 response rate, belimumab 10 mg had the best response efficacy, followed by anifrolumab 10 mg. However, there was no difference in the number of SAEs among the treatment options.
Objective: To determine the relative effectiveness and safety of belimumab and anifrolumab in patients with active systemic lupus erythematosus (SLE). Materials and methods: A Bayesian network meta-analysis was performed from randomized controlled trials (RCTs) on the effectiveness and safety of belimumab 10 mg, anifrolumab 300 mg, and a placebo in patients with active SLE. Results: Six RCTs (2,757 patients) were included in this study. The response rate based on the SLE 4 Responder Index (SRI4) at 52 weeks was substantially higher in the belimumab 10-mg and anifrolumab 300-mg groups than that in the placebo group (OR 2.90, % credible intervals (CrIs) 2.37 - 3.56; OR 1.60, % CrI 1.22 - 2.08). The SRI4 response rate for belimumab 10 mg was significantly higher than that for anifrolumab 300 mg (OR 1.82, 95% CrI 1.30 - 2.53). Ranking probability based on surface under the cumulative ranking curve (SUCRA) indicated that belimumab 10 mg was most likely the best treatment for SRI4 response (SUCRA = 0.999), followed by anifrolumab 300 mg (SUCRA = 0.500) and placebo (SUCRA = 0.001). The number of serious adverse events (SAEs) did not differ significantly among the 4 treatment groups. Conclusion: Based on the SRI4 response rate, belimumab 10 mg had the best response efficacy, followed by anifrolumab 10 mg. However, there was no difference in the number of SAEs among the treatment options.
Systemic lupus erythematosus (SLE) is a common autoimmune connective tissue disease with unclear etiology and pathogenesis. Mesenchymal stem cell (MSC) and MSC derived extracellular vesicles (EVs) play important roles in regulating innate and adaptive immunity, which are involved in many physiological and pathological processes and contribute to the immune homeostasis in SLE. The effects of MSCs and EVs on SLE have been drawing more and more attention during the past few years. This article reviews the immunomodulatory effects and underlying mechanisms of MSC/MSC-EVs in SLE, which provides novel insight into understanding SLE pathogenesis and guiding the biological therapy.
Lupus nephritis (LN) is the most frequent severe organ manifestation of systemic lupus erythematosus (SLE). About 30% of patients are refractory to treatment. The authors report a case of treatment of LN with interleukin-17-targeted therapy, demonstrating its possible benefit, after reports of T helper 17 cell involvement in SLE pathogenesis. We present the case of a childbearing age woman with SLE, who developed refractory LN despite all the indicated therapeutic options. During follow up, infection with human papillomavirus was detected, a possible trigger, and the following management was based on this discovery. We currently know that cytokines play a major role in tissue damage and interleukin-17 (IL-17) seems to be a fundamental key in SLE and LN, having shown its expression in renal glomeruli and urinary sediment. Thus, it was decided to start treatment with an anti-IL-17A antibody, secukinumab. After starting secukinumab, clinical and biological features improved and complete renal response was achieved.
Objectives: To characterize the relationship of anifrolumab pharmacokinetics with efficacy and safety in patients with moderate to severe SLE despite standard therapy, using pooled data from 2 phase 3 trials. Methods: TULIP-1 and TULIP-2 were randomized, placebo-controlled, 52-week trials of intravenous anifrolumab (every 4 weeks for 48 weeks). For the exposure-response analysis, BILAG-based Composite Lupus Assessment (BICLA) or SLE Responder Index (SRI[4]) response rates at week 52 in each quartile/tertile of average anifrolumab serum concentration (Cave) were compared for anifrolumab and placebo in all-comers, patients who completed treatment, and interferon gene signature (IFNGS)-high patients who completed treatment, using average marginal effect logistic regression. Relationships between exposure and key safety events were assessed graphically. Results: Of patients in TULIP-1/TULIP-2 who received anifrolumab (150 mg [n = 91], 300 mg [n = 356]) or placebo (n = 366), 574 completed treatment, of whom 470 were IFNGS high. In the exposure-efficacy analyses, BICLA and SRI(4) treatment differences favoring anifrolumab 300 mg vs placebo were observed across Cave subgroups and all analysis populations. Logistic regression identified Cave as a significant covariate for predicted BICLA response, as higher anifrolumab Cave predicted greater efficacy. There was no evidence of exposure-driven incidence of key safety events through week 52 in patients receiving anifrolumab 150 or 300 mg. Conclusion: While higher Cave predicted greater efficacy, consistent positive benefit favouring anifrolumab 300 mg vs placebo was observed in BICLA and SRI(4) responses across Cave subgroups in the TULIP trials. There was no evidence of exposure-driven safety events.
Objectives: To characterize the relationship of anifrolumab pharmacokinetics with efficacy and safety in patients with moderate to severe SLE despite standard therapy, using pooled data from 2 phase 3 trials. Methods: TULIP-1 and TULIP-2 were randomized, placebo-controlled, 52-week trials of intravenous anifrolumab (every 4 weeks for 48 weeks). For the exposure-response analysis, BILAG-based Composite Lupus Assessment (BICLA) or SLE Responder Index (SRI[4]) response rates at week 52 in each quartile/tertile of average anifrolumab serum concentration (Cave) were compared for anifrolumab and placebo in all-comers, patients who completed treatment, and interferon gene signature (IFNGS)-high patients who completed treatment, using average marginal effect logistic regression. Relationships between exposure and key safety events were assessed graphically. Results: Of patients in TULIP-1/TULIP-2 who received anifrolumab (150 mg [n = 91], 300 mg [n = 356]) or placebo (n = 366), 574 completed treatment, of whom 470 were IFNGS high. In the exposure-efficacy analyses, BICLA and SRI(4) treatment differences favoring anifrolumab 300 mg vs placebo were observed across Cave subgroups and all analysis populations. Logistic regression identified Cave as a significant covariate for predicted BICLA response, as higher anifrolumab Cave predicted greater efficacy. There was no evidence of exposure-driven incidence of key safety events through week 52 in patients receiving anifrolumab 150 or 300 mg. Conclusion: While higher Cave predicted greater efficacy, consistent positive benefit favouring anifrolumab 300 mg vs placebo was observed in BICLA and SRI(4) responses across Cave subgroups in the TULIP trials. There was no evidence of exposure-driven safety events.
Objectives: Level of βhCG and the presence of any uterine mass of hydatidiform mole need a careful review or monitoring in order to prevent metastasis, provide an early treatment and avoid unnecessary chemotherapy. Case presentation: A 36-year old fifth gravida patient who had a missed abortion was diagnosed as having a molar pregnancy with beta human chorionic gonadotrophin (βhCG) level of 509,921 IU/L. Her lung field was clear and she underwent suction and curettage (S & C) procedure. However, after six weeks, AA presented to the emergency department with a massive bleeding, although her βhCG level had decreased to 65,770 IU/L. A trans-abdominal ultrasound indicated the presence of an intra-uterine mass (3.0 × 4.4 cm). Nevertheless, her βhCG continued to show a declining trend (8,426 IU/L). AA was advised to undergo a chemotherapy but she refused, citing preference for alternative medicine like herbs instead. She opted for an "at own risk" (AOR) discharge with scheduled follow up. Subsequently, her condition improved with her βhCG showing a downward trend. Surprisingly, at six months post S & C, her βhCG ameliorated to 0 IU/L with no mass detected by ultrasound. Conclusions: Brucea javanica fruits, Pereskia bleo and Annona muricata leaves can potentially be useful alternatives to chemotherapy and need further studies.
Objective: To examine patients after embryo transfer for predictive influence of the human chorionic gonadotropin (hCG) level on the probability of finishing pregnancy with delivery. Methods: 490 patients pregnant after IVF + ET treatment placed in the study. The influence of other factors: age (patients 20-50), number of transferred embryos (one, two and more) and the length of cultivation on the probability of finishing pregnancy with delivery or loss and the possibility to predict multiple pregnancy was also related to the known hCG value. The transferred embryos were divided into two groups - early (cultivation 48 and 72 hrs) and prolonged cultivation (PC 96 and 120 hrs). The answer here, therefore, is a multinomial variable with four levels. For that reason the data was analysed through a multinomial logistic model vs. multinomial distribution of a mistake and generalised logistic link function. Results: The hCG level grows exponentially in the course of the 9th to 17th day after an embryo transfer (ET). The probability of one child delivery after the transfer of one embryo overdue after prolonged cultivation (96 or 120 hrs) grows with the average and above-average hCG values on the day of the draw. The hCG value was 678 (564-815) IU/l1 on the 14th day after ET in pregnancy ended in delivery, 321 (216-477) IU/l on average in abortion, 82 (51-132) IU/l in biochemical pregnancy and 1070 (737-1554) IU/l in multiple pregnancy. The probability of multiple pregnancy increased with hCG values greatly above the average and on the other hand, below-average values indicated abortion or biochemical pregnancy. The patients age was not proven to be of significant influence, the hCG level slightly decreased with higher age. On the contrary, an increasing frequency of abortions depending on the increasing age of the mother was once again confirmed. Conclusion: The measured hCG values are considerably different depending on the pregnancy result, which is why this value is considered a quality predictive factor of the pregnancy result.
Introduction: The presentation of Ectopic Pregnancy (EP) can be highly variable and serum Beta hCG estimation plays an important role in early diagnosis. Aim: Aim of the study was to determine the trends of hCG levels in EP and to explore the role of hCG in decisions related to management and follow-up of EPs. Materials and methods: A retrospective study of women who had EPs from January 2006 to December 2012 at an advanced tertiary care centre in southern India was carried out. These women had undergone treatment based on the hospital protocol. Results: The study identified 337 women with EP. Thirty one surgically confirmed cases were diagnosed below the discriminatory zone of 1500 mIU/ml. Among women who had Beta hCG estimations 48 hours apart, plateauing was observed in 22.5% while decrease >15% was noted in 26.8%. Almost half (47.9%) of the cases had an increase >15% and a few (2.8%) demonstrated an initial fall followed by a rise in titres. In 23.9% of these women, there was a rise >53% similar to intrauterine pregnancy. The average pre-treatment Beta hCG was 429.8, 3866.2 and 12961.5 mIU/ml for those who received expectant, medical and direct surgical treatment respectively. 43 women with relative contraindications received medical management and 39 were lost to follow-up after medical and expectant management. Excluding them, the success rate of these two modalities was 76.6% and 85.0% respectively. Conclusion: No single level of Beta hCG is diagnostic of EP and serial levels can demonstrate atypical trends in some cases. Hence, interpretation of these results should be done in conjunction with clinical and sonographic findings to arrive at a correct diagnosis.
The objective was to determine the strength of relationship between maternal free beta human chorionic gonadotropin (β-hCG) concentrations and rates of adverse pregnancy outcomes. Consecutive records of the database of our Down screening project were assessed for free β-hCG levels and pregnancy outcomes. Pregnancies with foetal chromosomal or structural anomalies and those with underlying disease were excluded. Free β-hCG levels of < 0.5, > 0.5 and < 2.0, and ≥ 2.0 MoM were categorised as low, normal and high, respectively. Of 17,082 screened women, 13,620 were available for analysis. In the first trimester (n = 8150), low β-hCG levels significantly increased risk for intrauterine growth restriction (IUGR), preterm birth, low birth weight (LBW) and low Apgar score with relative risk of 1.66, 1.43, 1.83 and 2.89; whereas high β-hCG group had a significant decreased risk of preterm birth and GDM with relative risk of 0.73 and 0.62. In the second trimester (n = 5470), both low and high β-hCG groups had significant increased risks of the most common adverse outcomes, i.e. spontaneous abortion, IUGR and preterm birth. In conclusion, abnormally low (< 0.5MoM) or high (> 2.0 MoM) free β-hCG levels are generally associated with an increased risk of adverse pregnancy outcomes. Nevertheless, high free β-hCG levels in the first trimester may possibly decrease risk of preterm delivery and GDM.
Human chorionic gonadotropin (hCG) is generally quantified in serum, but spot urine samples are also used to assess hCG levels in Japan. The purpose of the present study was to elucidate whether urinary hCG can be used clinically as a substitute for serum hCG. A total of 189 samples of serum and spot urine were collected from patients, including cases of normal pregnancy (NP) -13, abortion (AB) -21, extrauterine pregnancy (EP) 25, and hydatidiform mole (MOL) -7, during medical treatment and comparisons were made concerning serum and urinary hCG levels. The histogram of relative urinary/serum hCG(U-hCG.act/S-hCG) of the samples showed a wide distribution of values, but tended to converge to a narrow distribution by creatinine correction (U-hCG.cor/S-hCG). U-hCG.cor/S-hCG of the AB, EP, and MOL groups decreased 1 day to 14 days or was no earlier than 15 days postoperatively compared to preoperatively. The alteration of serum Intact/Total tended to be similar to that of U-hCG.cor/S-hCG in clinical course. The presented case indicated that U-hCG.act/S-hCG did not correspond to serum hCG levels. Because urinary hCG levels are inconsistent depending on whether spot urine is concentrated or diluted, the levels of hCG in spot urine do not always correlate with serum levels of hCG. Therefore, the data of urinary hCG should be interpreted after creatinine correction. Overall, it is recommended to determine serum hCG levels rather than creatinine corrected urinary hCG levels, considering that the relative urinary/serum hCG was not constant postoperatively.
Objective: The aim of this study was to investigate whether subfertility, measured as longer time-to-pregnancy (TTP) in spontaneously conceived pregnancies, affects the first trimester levels of pregnancy-associated plasma protein-A (PAPP-A) and free beta-human chorionic gonadotrophin (β-hCG) and hence the risk estimates in Down syndrome screening. Methods: The study included a cohort of 10 469 singleton pregnant women who underwent first trimester combined screening and responded to a questionnaire regarding TTP. PAPP-A and free β-hCG levels were measured between gestational week 8 + 0 and 13 + 6 and were related to TTP. Results: The median PAPP-A and free β-hCG MoMs were significantly lower in women with a TTP ≥24 months compared with the reference group with a TTP <6 months (PAPP-A: 0.96 vs 1.06 MoM, p = 0.003; free β-hCG: 1.04 vs 1.12 MoM, p = 0.03). This led to an increased odds for trisomy 21 risk ≥1 : 300 for TTP ≥24 months compared with TTP <6 months, but when adjusting for potential confounders, the odds ratio (OR) lost significance (OR 1.4, 95% confidence interval; 0.8-2.4). Conclusion: Time-to-pregnancy ≥24 months in spontaneously conceived pregnancies is associated with decreased levels of PAPP-A and free β-hCG.
Human chorionic gonadotropin (hCG) is a chemical created by trophoblast tissue, tissue typically found in early embryos and which will eventually be part of the placenta. Measuring hCG levels can be helpful in identifying a normal pregnancy, pathologic pregnancy, and can also be useful following an aborted pregnancy. There is also a benefit in measuring hCG in a variety of cancers including choriocarcinoma and extra-uterine malignancies.
Human chorionic gonadotropin (hCG) is a pregnancy hormone secreted by the placental synctiotrophoblast cell layer that has been linked to fetal growth and various placental, uterine and fetal functions. In order to investigate the effects of hCG on clinical endpoints, knowledge on reference range (RR) methodology and determinants of gestational hCG levels is crucial. Moreover, a better understanding of gestational hCG physiology can improve current screening programs and future clinical management. Serum total hCG levels were determined in 8195 women participating in the Generation R Study. Gestational age specific RRs using 'ultrasound derived gestational age' (US RRs) were calculated and compared with 'last menstrual period derived gestational age' (LMP RRs) and a model-based RR. We also investigated which pregnancy characteristics were associated with hCG levels. Compared to the US RRs, the LMP RRs were lower, most notably for the median and lower limit levels. No considerable differences were found between RRs calculated in the general population or in uncomplicated pregnancies only. Maternal smoking, BMI, parity, ethnicity, fetal gender, placental weight and hyperemesis gravidarum symptoms were associated with total hCG. We provide gestational RRs for total hCG and show that total hCG values and RR cut-offs during pregnancy vary depending on pregnancy dating methodology. This is likely due to the influence of hCG on embryonic growth, suggesting that ultrasound based pregnancy dating might be less reliable in women with high/low hCG levels. Furthermore, we identify different pregnancy characteristics that influence total hCG levels considerably and should therefore be accounted for in clinical studies.
Family physicians often use quantitative human chorionic gonadotropin (HCG) testing to assess first-trimester bleeding. While we anticipate a range of normal results for any given week in the first trimester, we predict an approximate doubling over 48 hours in a normal pregnancy during the first trimester. Human chorionic gonadotropin tends to peak at about 10 weeks’ gestation before declining and stabilizing. When HCG levels plateau prematurely or fail to rise as expected, we consider that the pregnancy might not be viable.
The first trimester screening programme offers a noninvasive option for the early detection of aneuploidy pregnancies. This screening is done by a combination of two biochemical markers i.e. serum free β-human chorionic gonadotrophin (free β-hCG) and pregnancy associated plasma protein A (PAPP-A), maternal age and fetal nuchal translucency (NT) thickness at 11 + 0-13 + 6 weeks of gestation. A beneficial consequence of screening is the early diagnosis or trisomies 21, 18 and 13. At 11 + 0-13 + 6 weeks, the relative prevalence of trisomies 18 and 13 to trisomy 21 are found to be one to three and one to seven, respectively. All three trisomies are associated with increased maternal age, increased fetal NT and decreased PAPP-A, but in trisomy 21 serum free β-hCG is increased whereas in trisomies 18 and 13 free β-hCG is decreased.
The comparative absorption of zinc after oral administration of three different complexed forms was studied in 15 healthy human volunteers in a double-blind four-period crossover trial. The individuals were randomly divided into four groups. Each group rotated for four week periods through a random sequence of oral supplementation including: zinc picolinate, zinc citrate, and zinc gluconate (equivalent to 50 mg elemental zinc per day) and placebo. Zinc was measured in hair, urine, erythrocyte and serum before and after each period. At the end of four weeks hair, urine and erythrocyte zinc levels rose significantly (p less than 0.005, p less than 0.001, and p less than 0.001) during zinc picolinate administration. There was no significant change in any of these parameters from zinc gluconate, zinc citrate or placebo administration. There was a small, insignificant rise in serum zinc during zinc picolinate, zinc citrate and placebo supplementation. The results of this study suggest that zinc absorption in humans can be improved by complexing zinc with picolinic acid.
The comparative absorption of zinc after oral administration of three different complexed forms was studied in 15 healthy human volunteers in a double-blind four-period crossover trial. The individuals were randomly divided into four groups. Each group rotated for four week periods through a random sequence of oral supplementation including: zinc picolinate, zinc citrate, and zinc gluconate (equivalent to 50 mg elemental zinc per day) and placebo. Zinc was measured in hair, urine, erythrocyte and serum before and after each period. At the end of four weeks hair, urine and erythrocyte zinc levels rose significantly (p less than 0.005, p less than 0.001, and p less than 0.001) during zinc picolinate administration. There was no significant change in any of these parameters from zinc gluconate, zinc citrate or placebo administration. There was a small, insignificant rise in serum zinc during zinc picolinate, zinc citrate and placebo supplementation. The results of this study suggest that zinc absorption in humans can be improved by complexing zinc with picolinic acid.
The anti-VSC (volatile sulphur compounds) effect of zinc is known to be associated with free zinc ions. Objective: To examine whether zinc salts with low stability constants were more suitable as sources of zinc in zinc lozenges than zinc salts with high stability constants. The former provide free zinc ions upon dissolution in water, whereas the latter provide few such ions. Design and participants: Identical lozenges were produced which contained either zinc acetate, zinc gluconate (low stability constants), zinc citrate or amino-acid chelated zinc (extremely high stability constants). All the lozenges contained 0.1 per cent of zinc. A test panel of 10 volunteers used the different lozenges randomly. VSC were measured by GC. Results and conclusion: The lozenge with the highest stability constant was as effective as those with very low stability constants. The anti-VSC effect was thus not related to this constant. These findings may be explained by the possibility that alternative ligands with stronger affinity for zinc than the original ligands in the lozenges may be present in the oral cavity. An in vitro experiment indicated that the sulphide ion (S2-) may be such a ligand.
The anti-VSC (volatile sulphur compounds) effect of zinc is known to be associated with free zinc ions. Objective: To examine whether zinc salts with low stability constants were more suitable as sources of zinc in zinc lozenges than zinc salts with high stability constants. The former provide free zinc ions upon dissolution in water, whereas the latter provide few such ions. Design and participants: Identical lozenges were produced which contained either zinc acetate, zinc gluconate (low stability constants), zinc citrate or amino-acid chelated zinc (extremely high stability constants). All the lozenges contained 0.1 per cent of zinc. A test panel of 10 volunteers used the different lozenges randomly. VSC were measured by GC. Results and conclusion: The lozenge with the highest stability constant was as effective as those with very low stability constants. The anti-VSC effect was thus not related to this constant. These findings may be explained by the possibility that alternative ligands with stronger affinity for zinc than the original ligands in the lozenges may be present in the oral cavity. An in vitro experiment indicated that the sulphide ion (S2-) may be such a ligand.
Currently much attention has been given to the neurotoxicity of zinc, yet little is known about the influence of the counterions present. Therefore, we investigated the influence of different Zn(2+)-salts (concentrations range 0.05-0.3 mM) on cell viability, ATP and glutathione concentration and caspase activation in differentiated PC12 cells as a model for neuronal cells. Generally, at concentrations of 0.05 mM most Zn(2+)-salts were not cytotoxic except for zinc-citrate. At concentrations between 0.1 and 0.3 mM Zn(2+) a significant decrease in GSH and ATP levels preceded cell death induced by all salts, except of zinc-histidinate. Zinc-citrate and zinc-sulphate turned out to be the most toxic salts particularly at low concentrations. Analyses of caspase 3/7 activity showed that dependent on the concentration and the type of the salt used cell death may show more or less signs of both, necrosis and apoptosis. Interestingly, the uptake of Zn(2+) from zinc-sulphate and zinc-citrate was significantly higher than that of other salts, implicating a correlation between uptake and toxicity. In conclusion, Zn(2+)-salts could be divided into three categories with high (zinc-citrate, zinc-sulphate), moderate (zinc-orotate, zinc-acetate, zinc-chloride(,) zinc-gluconate) and low cytotoxicity (zinc-histidinate).
Currently much attention has been given to the neurotoxicity of zinc, yet little is known about the influence of the counterions present. Therefore, we investigated the influence of different Zn(2+)-salts (concentrations range 0.05-0.3 mM) on cell viability, ATP and glutathione concentration and caspase activation in differentiated PC12 cells as a model for neuronal cells. Generally, at concentrations of 0.05 mM most Zn(2+)-salts were not cytotoxic except for zinc-citrate. At concentrations between 0.1 and 0.3 mM Zn(2+) a significant decrease in GSH and ATP levels preceded cell death induced by all salts, except of zinc-histidinate. Zinc-citrate and zinc-sulphate turned out to be the most toxic salts particularly at low concentrations. Analyses of caspase 3/7 activity showed that dependent on the concentration and the type of the salt used cell death may show more or less signs of both, necrosis and apoptosis. Interestingly, the uptake of Zn(2+) from zinc-sulphate and zinc-citrate was significantly higher than that of other salts, implicating a correlation between uptake and toxicity. In conclusion, Zn(2+)-salts could be divided into three categories with high (zinc-citrate, zinc-sulphate), moderate (zinc-orotate, zinc-acetate, zinc-chloride(,) zinc-gluconate) and low cytotoxicity (zinc-histidinate).
Background: There is a clinical need for new therapeutic products against Herpes simplex virus (HSV). The pomegranate, fruit of the tree Punica granatum L, has since ancient times been linked to activity against infection. This work probed the activity of pomegranate rind extract (PRE) and co-administered zinc (II) ions. Materials and methods: PRE was used in conjunction with zinc (II) salts to challenge HSV-1 and aciclovir-resistant HSV in terms of virucidal plaque assay reduction and antiviral activities in epithelial Vero host cells. Cytotoxicity was determined by the MTS assay using a commercial kit. Results: Zinc sulphate, zinc citrate, zinc stearate and zinc gluconate demonstrated similar potentiated virucidal activity with PRE against HSV-1 by up to 4-fold. A generally parabolic relationship was observed when HSV-1 was challenged with PRE and varying concentrations of ZnSO4, with a maximum potentiation factor of 5.5. Punicalagin had 8-fold greater virucidal activity than an equivalent mass of PRE. However, antiviral data showed that punicalagin had significantly lower antiviral activity compared to the activity of PRE (EC50 = 0.56 μg mL-1) a value comparable to aciclovir (EC50 = 0.18 μg mL-1); however, PRE also demonstrated potency against aciclovir-resistant HSV (EC50 = 0.02 μg mL-1), whereas aciclovir showed no activity. Antiviral action of PRE was not influenced by ZnSO4. No cytotoxicity was detected with any test solution. Conclusions: The potentiated virucidal activity of PRE by coadministered zinc (II) has potential as a multi-action novel topical therapeutic agent against HSV infections, such as coldsores.
Background: There is a clinical need for new therapeutic products against Herpes simplex virus (HSV). The pomegranate, fruit of the tree Punica granatum L, has since ancient times been linked to activity against infection. This work probed the activity of pomegranate rind extract (PRE) and co-administered zinc (II) ions. Materials and methods: PRE was used in conjunction with zinc (II) salts to challenge HSV-1 and aciclovir-resistant HSV in terms of virucidal plaque assay reduction and antiviral activities in epithelial Vero host cells. Cytotoxicity was determined by the MTS assay using a commercial kit. Results: Zinc sulphate, zinc citrate, zinc stearate and zinc gluconate demonstrated similar potentiated virucidal activity with PRE against HSV-1 by up to 4-fold. A generally parabolic relationship was observed when HSV-1 was challenged with PRE and varying concentrations of ZnSO4, with a maximum potentiation factor of 5.5. Punicalagin had 8-fold greater virucidal activity than an equivalent mass of PRE. However, antiviral data showed that punicalagin had significantly lower antiviral activity compared to the activity of PRE (EC50 = 0.56 μg mL-1) a value comparable to aciclovir (EC50 = 0.18 μg mL-1); however, PRE also demonstrated potency against aciclovir-resistant HSV (EC50 = 0.02 μg mL-1), whereas aciclovir showed no activity. Antiviral action of PRE was not influenced by ZnSO4. No cytotoxicity was detected with any test solution. Conclusions: The potentiated virucidal activity of PRE by coadministered zinc (II) has potential as a multi-action novel topical therapeutic agent against HSV infections, such as coldsores.
The normal human prostate accumulates the highest levels of zinc (Zn) of any soft tissue in the body. The pool of zinc available to the body is known to significantly decrease with age. It is suggested that dietary Zn supplementation protects against oxidative damage and reduces the risk of cancer. Zinc sulfate and zinc gluconate were the most frequently mentioned in per os administration in studies on Zn supplementation. The major aim of the study was to compare the bioavailability of different Zn compounds (sulfate, gluconate and citrate) in the prostate after their daily administration to male rats at three different doses (3.0; 15.0; and 50.0 mg Zn/kg b.w.) for 30 days. The results show that bioavailability in the prostate differs significantly between individual zinc preparations. A significantly elevated Zn concentration in the dorso-lateral lobe of the prostate, compared to controls, was found in the rats supplemented with two compounds only: zinc gluconate and zinc citrate. However, after administration of zinc gluconate, this effect occurred even at the lowest dose. The lowest zinc bioavailability in the prostate was found in the rats administered zinc sulfate: no significant Zn increase was seen in particular zones of the prostate. To sum up, the use of zinc gluconate is worth considering as a possible means of zinc supplementation in men.
The normal human prostate accumulates the highest levels of zinc (Zn) of any soft tissue in the body. The pool of zinc available to the body is known to significantly decrease with age. It is suggested that dietary Zn supplementation protects against oxidative damage and reduces the risk of cancer. Zinc sulfate and zinc gluconate were the most frequently mentioned in per os administration in studies on Zn supplementation. The major aim of the study was to compare the bioavailability of different Zn compounds (sulfate, gluconate and citrate) in the prostate after their daily administration to male rats at three different doses (3.0; 15.0; and 50.0 mg Zn/kg b.w.) for 30 days. The results show that bioavailability in the prostate differs significantly between individual zinc preparations. A significantly elevated Zn concentration in the dorso-lateral lobe of the prostate, compared to controls, was found in the rats supplemented with two compounds only: zinc gluconate and zinc citrate. However, after administration of zinc gluconate, this effect occurred even at the lowest dose. The lowest zinc bioavailability in the prostate was found in the rats administered zinc sulfate: no significant Zn increase was seen in particular zones of the prostate. To sum up, the use of zinc gluconate is worth considering as a possible means of zinc supplementation in men.
The water-soluble zinc salts gluconate, sulfate, and acetate are commonly used as supplements in tablet or syrup form to prevent zinc deficiency and to treat diarrhea in children in combination with oral rehydration. Zinc citrate is an alternative compound with high zinc content, slightly soluble in water, which has better sensory properties in syrups but no absorption data in humans. We used the double-isotope tracer method with (67) Zn and (70) Zn to measure zinc absorption from zinc citrate given as supplements containing 10 mg of zinc to 15 healthy adults without food and compared absorption with that from zinc gluconate and zinc oxide (insoluble in water) using a randomized, double-masked, 3-way crossover design. Median (IQR) fractional absorption of zinc from zinc citrate was 61.3% (56.6-71.0) and was not different from that from zinc gluconate with 60.9% (50.6-71.7). Absorption from zinc oxide at 49.9% (40.9-57.7) was significantly lower than from both other supplements (P < 0.01). Three participants had little or no absorption from zinc oxide. We conclude that zinc citrate, given as a supplement without food, is as well absorbed by healthy adults as zinc gluconate and may thus be a useful alternative for preventing zinc deficiency and treating diarrhea. The more insoluble zinc oxide is less well absorbed when given as a supplement without food and may be minimally absorbed by some individuals.
The water-soluble zinc salts gluconate, sulfate, and acetate are commonly used as supplements in tablet or syrup form to prevent zinc deficiency and to treat diarrhea in children in combination with oral rehydration. Zinc citrate is an alternative compound with high zinc content, slightly soluble in water, which has better sensory properties in syrups but no absorption data in humans. We used the double-isotope tracer method with (67) Zn and (70) Zn to measure zinc absorption from zinc citrate given as supplements containing 10 mg of zinc to 15 healthy adults without food and compared absorption with that from zinc gluconate and zinc oxide (insoluble in water) using a randomized, double-masked, 3-way crossover design. Median (IQR) fractional absorption of zinc from zinc citrate was 61.3% (56.6-71.0) and was not different from that from zinc gluconate with 60.9% (50.6-71.7). Absorption from zinc oxide at 49.9% (40.9-57.7) was significantly lower than from both other supplements (P < 0.01). Three participants had little or no absorption from zinc oxide. We conclude that zinc citrate, given as a supplement without food, is as well absorbed by healthy adults as zinc gluconate and may thus be a useful alternative for preventing zinc deficiency and treating diarrhea. The more insoluble zinc oxide is less well absorbed when given as a supplement without food and may be minimally absorbed by some individuals.
Objective: Zinc supplementation is beneficial in some clinical conditions such as age-related macula degeneration (AMD). It has been suggested that zinc absorption is influenced by the form in which zinc is ingested. Therefore, the pharmacokinetics of zinc gluconate (organic) were compared with those of zinc oxide (inorganic). Methods: 12 healthy male subjects aged between 21 and 31 years (24 years median) orally received daily doses of 20 mg metal zinc as zinc gluconate and 17.4 mg metal zinc as zinc oxide under randomized crossover conditions for 14 days each with at least 14 days as a washout. Zinc plasma concentrations were measured by means of inductively coupled plasma-atomic emission spectroscopy. Results: C(max) was found 18.3% (10.3 - 26.3%) higher following multiple-dose administration of zinc gluconate as compared to zinc oxide (mean; 0.95% confidence interval of the relative differences between both treatment conditions; p < 0.05). AUC(0-24h) was noted 8.1% (1.9 - 14.3%) higher after zinc was given as zinc gluconate when compared to zinc oxide (p < 0.05) whereas t(max) did not differ between both treatment conditions. Conclusions: Zinc absorption in humans could be improved by zinc complexation with gluconate.
Objective: Zinc supplementation is beneficial in some clinical conditions such as age-related macula degeneration (AMD). It has been suggested that zinc absorption is influenced by the form in which zinc is ingested. Therefore, the pharmacokinetics of zinc gluconate (organic) were compared with those of zinc oxide (inorganic). Methods: 12 healthy male subjects aged between 21 and 31 years (24 years median) orally received daily doses of 20 mg metal zinc as zinc gluconate and 17.4 mg metal zinc as zinc oxide under randomized crossover conditions for 14 days each with at least 14 days as a washout. Zinc plasma concentrations were measured by means of inductively coupled plasma-atomic emission spectroscopy. Results: C(max) was found 18.3% (10.3 - 26.3%) higher following multiple-dose administration of zinc gluconate as compared to zinc oxide (mean; 0.95% confidence interval of the relative differences between both treatment conditions; p < 0.05). AUC(0-24h) was noted 8.1% (1.9 - 14.3%) higher after zinc was given as zinc gluconate when compared to zinc oxide (p < 0.05) whereas t(max) did not differ between both treatment conditions. Conclusions: Zinc absorption in humans could be improved by zinc complexation with gluconate.
Zinc (Zn)-enriched yeast and gluconate are considered two of the more biologically available supplements. However, there have been few reports comparing the bioavailability of these supplements. The objective of this study was to demonstrate whether Zn was absorbed better by healthy male volunteers when given supplements where the mineral is found organically bound in yeast or as a salt gluconate form. The trial used a randomized, two-way crossover design. Urine, blood, and fecal samples were collected and analyzed over a 48-h period after a single dose of supplement. The net Zn balance and the relative bioavailability were calculated. No differences were observed in urine excretion of the two supplements. Zinc gluconate gave higher Zn concentrations in the blood in the first 6 h but also showed greater losses in the feces. Zinc yeast also increased in blood with time but showed significantly less loss in the feces. Thus, the net Zn balance after 48 h for Zn yeast was 9.46 but for Zn gluconate it was -2.00, indicating that Zn gluconate supplementation contributed to a net loss of Zn. It was concluded that organic Zn yeast supplements are more biologically available than Zn gluconate salts.
Zinc (Zn)-enriched yeast and gluconate are considered two of the more biologically available supplements. However, there have been few reports comparing the bioavailability of these supplements. The objective of this study was to demonstrate whether Zn was absorbed better by healthy male volunteers when given supplements where the mineral is found organically bound in yeast or as a salt gluconate form. The trial used a randomized, two-way crossover design. Urine, blood, and fecal samples were collected and analyzed over a 48-h period after a single dose of supplement. The net Zn balance and the relative bioavailability were calculated. No differences were observed in urine excretion of the two supplements. Zinc gluconate gave higher Zn concentrations in the blood in the first 6 h but also showed greater losses in the feces. Zinc yeast also increased in blood with time but showed significantly less loss in the feces. Thus, the net Zn balance after 48 h for Zn yeast was 9.46 but for Zn gluconate it was -2.00, indicating that Zn gluconate supplementation contributed to a net loss of Zn. It was concluded that organic Zn yeast supplements are more biologically available than Zn gluconate salts.
Unlike iron, zinc absorption is influenced by dietary zinc intake, not zinc status. As dietary zinc increases, the total amount of absorbed zinc increases while the percent absorbed declines. The gastrointestinal tract maintains whole-body zinc homeostasis by adjusting endogenous zinc losses to the amount absorbed. At intakes below about 9 mg/day, zinc absorption occurs primarily by a saturable (carrier) process involving ZIP4, ZnT1, and other transporters. There is no evidence that past zinc intakes, or status, influences zinc absorption. Instead, current zinc intake is the chief determinant of zinc absorption. Supplemental zinc taken with water in the post-absorptive state initially is absorbed more efficiently than food zinc, but absorption efficiency declines within 24 hours presumably due to down-regulation of the zinc transporters. More research is needed to understand the effect of physiological state on zinc absorption.
Unlike iron, zinc absorption is influenced by dietary zinc intake, not zinc status. As dietary zinc increases, the total amount of absorbed zinc increases while the percent absorbed declines. The gastrointestinal tract maintains whole-body zinc homeostasis by adjusting endogenous zinc losses to the amount absorbed. At intakes below about 9 mg/day, zinc absorption occurs primarily by a saturable (carrier) process involving ZIP4, ZnT1, and other transporters. There is no evidence that past zinc intakes, or status, influences zinc absorption. Instead, current zinc intake is the chief determinant of zinc absorption. Supplemental zinc taken with water in the post-absorptive state initially is absorbed more efficiently than food zinc, but absorption efficiency declines within 24 hours presumably due to down-regulation of the zinc transporters. More research is needed to understand the effect of physiological state on zinc absorption.
Zinc has earned recognition recently as a micronutrient of outstanding and diverse biological, clinical, and global public health importance. Regulation of absorption by zinc transporters in the enterocyte, together with saturation kinetics of the absorption process into and across the enterocyte, are the principal means by which whole-body zinc homeostasis is maintained. Several physiologic factors, most notably the quantity of zinc ingested, determine the quantity of zinc absorbed and the efficiency of absorption. Other factors are age and the time over which zinc is ingested. Zinc from supplements has not been shown to be absorbed differently from that taken with meals that lack inhibitors of zinc absorption. The principal dietary factor known to impair zinc bioavailability is inositol hexa- (and penta-) phosphate or phytate. Modeling of zinc absorption as a function of dietary zinc and phytate accounts for >80% of the variability in the quantity of zinc absorbed. Fitting the model to new data has resulted in continual improvement in parameter estimates, which currently indicate a maximal absorption in adults of approximately 6 mg Zn/d and that the average estimated dietary requirement doubles with 1000 mg dietary phytate/d. Intestinal excretion of endogenous zinc is regulated in response to recent absorption and to zinc status. The quantitative relation of intestinal excretion of endogenous zinc to zinc absorption is currently considered to be of major importance in the determination of zinc requirements. The effects of phytate on intestinal losses of endogenous zinc merit further investigation but are probably not of the same magnitude as its inhibitory effects on absorption of exogenous zinc.
Zinc has earned recognition recently as a micronutrient of outstanding and diverse biological, clinical, and global public health importance. Regulation of absorption by zinc transporters in the enterocyte, together with saturation kinetics of the absorption process into and across the enterocyte, are the principal means by which whole-body zinc homeostasis is maintained. Several physiologic factors, most notably the quantity of zinc ingested, determine the quantity of zinc absorbed and the efficiency of absorption. Other factors are age and the time over which zinc is ingested. Zinc from supplements has not been shown to be absorbed differently from that taken with meals that lack inhibitors of zinc absorption. The principal dietary factor known to impair zinc bioavailability is inositol hexa- (and penta-) phosphate or phytate. Modeling of zinc absorption as a function of dietary zinc and phytate accounts for >80% of the variability in the quantity of zinc absorbed. Fitting the model to new data has resulted in continual improvement in parameter estimates, which currently indicate a maximal absorption in adults of approximately 6 mg Zn/d and that the average estimated dietary requirement doubles with 1000 mg dietary phytate/d. Intestinal excretion of endogenous zinc is regulated in response to recent absorption and to zinc status. The quantitative relation of intestinal excretion of endogenous zinc to zinc absorption is currently considered to be of major importance in the determination of zinc requirements. The effects of phytate on intestinal losses of endogenous zinc merit further investigation but are probably not of the same magnitude as its inhibitory effects on absorption of exogenous zinc.
Iron is a micronutrient essential for a wide range of metabolic processes in virtually all living organisms. During infections, a battle for iron takes place between the human host and the invading pathogens. The liver peptide hepcidin, which is phylogenetically and structurally linked to defensins (antimicrobial peptides of the innate immunity), plays a pivotal role by subtracting iron to pathogens through its sequestration into host cells, mainly macrophages. While this phenomenon is well studied in certain bacterial infections, much less is known regarding viral infections. Iron metabolism also has implications on the functionality of cells of the immune system. Once primed by the contact with antigen presenting cells, lymphocytes need iron to sustain the metabolic burst required for mounting an effective cellular and humoral response. The COVID-19 pandemic has boosted an amount of clinical and translational research over the possible influences of nutrients on SARS-CoV-2 infection, in terms of either susceptibility or clinical course. Here we review the intersections between iron metabolism and COVID-19, belonging to the wider domain of the so-called "nutritional immunity". A better understanding of such connections has potential broad implications, either from a mechanistic standpoint, or for the development of more effective strategies for managing COVID-19 and possible future pandemics.
Background and aims: Iron is an essential trace element to almost all organism, and the delicate balance between host defend system and viral proliferation plays an important role in infective conditions. While the association of the iron metabolism with the prognosis of COVID-19 remains poorly understood. We aimed to estimate the associations of systemic iron metabolism parameters with the severity and risks of adverse outcomes in COVID-19. Methods: In this retrospective cohort study, we included 158 confirmed COVID-19 patients in Tongji Hospital, Wuhan, China (27 January to 5 April, 2020). Demographic data, comorbidities, laboratory examinations, treatments, and clinical outcomes were all collected. Multivariable Poisson regression was used to estimate the association of iron parameter levels with the severity and risks of adverse outcomes in COVID-19 patients. Results: We identified 60 (38%) severe cases in 158 COVID-19 patients. The median age was 63 years (interquartile range [IQR]: 54-73) and the median length of hospital stay was 28 days (IQR: 17-40). After adjusting for age, sex, IL-6, and pre-existing comorbidities, all iron parameters were associated with the severity of COVID-19 with adjusted risk ratio of 0.42 [95% CI: 0.22-0.83], 4.38 [95% CI: 1.86-10.33], 0.19 [95% CI: 0.08-0.48], and 0.25 [95% CI: 0.10-0.58] for serum iron, ferritin, transferrin, and total iron-binding capacity, respectively. These iron indices were also related to the risk of ARDS, coagulopathy, acute cardiac injury, acute liver injury, and acute kidney injury in COVID-19 patients and high cytokine concentrations. Conclusions: Patients with low serum iron status likely suffered from severe condition and multiple-organ injury in COVID-19. The iron metabolism parameters might be risk factors and clinical biomarkers for COVID-19 prognosis.
Large variability in COVID-19 clinical progression urges the need to find the most relevant biomarkers to predict patients' outcomes. We evaluated iron metabolism and immune response in 303 patients admitted to the main hospital of the northern region of Portugal with variable clinical pictures, from September to November 2020. One hundred and twenty-seven tested positive for SARS-CoV-2 and 176 tested negative. Iron-related laboratory parameters and cytokines were determined in blood samples collected soon after admission. Demographic data, comorbidities and clinical outcomes were recorded. Patients were assigned into five groups according to severity. Serum iron and transferrin levels at admission were lower in COVID-19-positive than in COVID-19-negative patients. The levels of interleukin (IL)-6 and monocyte chemoattractant protein 1 (MCP-1) were increased in COVID-19-positive patients. The lowest serum iron and transferrin levels at diagnosis were associated with the worst outcomes. Iron levels negatively correlated with IL-6 and higher levels of this cytokine were associated with a worse prognosis. Serum ferritin levels at diagnosis were higher in COVID-19-positive than in COVID-19-negative patients. Serum iron is the simplest laboratory test to be implemented as a predictor of disease progression in COVID-19-positive patients.
This report provides perspectives concerning dual roles of serum ferritin as a measure of both iron status and inflammation. We suggest benefits of a lower range of serum ferritin as has occurred for total serum cholesterol and fasting blood glucose levels. Observations during a prospective randomized study using phlebotomy in patients with peripheral arterial disease offered unique insights into dual roles of serum ferritin both as an iron status marker and acute phase reactant. Robust positive associations between serum ferritin, interleukin 6 [IL-6], tissue necrosis factor-alpha, and high sensitivity C-reactive protein were discovered. Elevated serum ferritin and IL-6 levels associated with increased mortality and with reduced mortality at ferritin levels <100 ng mL-1. Epidemiologic studies demonstrate similar outcomes. Extremely elevated ferritin and IL-6 levels also occur in individuals with high mortality due to SARS-CoV-2 infection. Disordered iron metabolism reflected by a high range of serum ferritin level signals disease severity and outcomes. Based upon experimental and epidemiologic data, we suggest testing the hypotheses that optimal ferritin levels for cardiovascular mortality reduction range from 20 to 100 ng mL-1 with % transferrin levels from 20 to 50%, to ensure adequate iron status and that ferritin levels above 194 ng mL-1 associate with all-cause mortality in population cohorts.
While it took decades to arrive to a conclusion that ferritin is more than an indicator of iron storage level, it took a short period of time through the COVID-19 pandemic to wonder what the reason behind high levels of ferritin in patients with severe COVID-19 might be. Unsurprisingly, acute phase reactant was not a satisfactory explanation. Moreover, the behavior of ferritin in patients with severe COVID-19 and the subsequent high mortality rates in patients with high ferritin levels necessitated further investigations to understand the role of ferritin in the diseases. Ferritin was initially described to accompany various acute infections, both viral and bacterial, indicating an acute response to inflammation. However, with the introduction of the hyperferritinemic syndrome connecting four severe pathological conditions such as adult-onset Still's disease, macrophage activation syndrome, catastrophic antiphospholipid syndrome, and septic shock added another aspect of ferritin where it could have a pathogenetic role rather than an extremely elevated protein only. In fact, suggesting that COVID-19 is a new member in the spectrum of hyperferritinemic syndrome besides the four mentioned conditions could hopefully direct further search on the pathogenetic role of ferritin. Doubtlessly, improving our understanding of those aspects of ferritin would enormously contribute to better coping with severe diseases in terms of treatment and prevention of complications. The origin, history, importance, and the advances of searching the role of ferritin in various pathological and clinical processes are presented hereby in our article. In addition, the implications of ferritin in COVID-19 are addressed.
SARS-CoV-2 infection is characterized by a protean clinical picture that can range from asymptomatic patients to life-threatening conditions. Severe COVID-19 patients often display a severe pulmonary involvement and develop neutrophilia, lymphopenia, and strikingly elevated levels of IL-6. There is an over-exuberant cytokine release with hyperferritinemia leading to the idea that COVID-19 is part of the hyperferritinemic syndrome spectrum. Indeed, very high levels of ferritin can occur in other diseases including hemophagocytic lymphohistiocytosis, macrophage activation syndrome, adult-onset Still's disease, catastrophic antiphospholipid syndrome and septic shock. Numerous studies have demonstrated the immunomodulatory effects of ferritin and its association with mortality and sustained inflammatory process. High levels of free iron are harmful in tissues, especially through the redox damage that can lead to fibrosis. Iron chelation represents a pillar in the treatment of iron overload. In addition, it was proven to have an anti-viral and anti-fibrotic activity. Herein, we analyse the pathogenic role of ferritin and iron during SARS-CoV-2 infection and propose iron depletion therapy as a novel therapeutic approach in the COVID-19 pandemic.
Background: Several studies have suggested that COVID-19 is a systemic disease that can affect several organs, including the brain. In the brain, specifically, viral infection can cause dyshomeostasis of some trace elements that promote complex biochemical reactions in specialized neurological functions. Objective: Understand the neurovirulence of SARS-CoV-2 and the relationship between trace elements and neurological disorders after infection, and provide new insights on the drug development for the treatment of SARS-CoV-2 infections. Methods: The main databases were used to search studies published up September 2021, focusing on the role of trace elements during viral infection and on the correct functioning of the brain. Results: The imbalance of important trace elements can accelerate SARS-CoV-2 neurovirulence and increase the neurotoxicity since many neurological processes can be associated with the homeostasis of metal and metalloproteins. Some studies involving animals and humans have suggested the synapse as a vulnerable region of the brain to neurological disorders after viral infection. Considering the combined evidence, some mechanisms have been suggested to understand the relationship between neurological disorders and imbalance of trace elements in the brain after viral infection. Conclusion: Trace elements play important roles in viral infections, such as helping to activate immune cells, produce antibodies, and inhibit virus replication. However, the relationship between trace elements and virus infections is complex since the specific functions of several elements remain largely undefined. Therefore, there is still a lot to be explored to understand the biochemical mechanisms involved between trace elements and viral infections, especially in the brain.
The importance of ferritin as an inflammatory marker is well recognized. However, it is unknown whether this differs between Covid-19 and non-Covid-19 patients. The blood levels of ferritin, white blood cells (WBC), C-reactive protein (CRP), and lactate dehydrogenase may all be measured to check whether there is a difference. The researchers want to see if the inflammatory process changes between these two kinds (LDH). Methodology: Blood samples were collected from 119 COVID-19 patients in the hospital and 50 healthy persons. Corona virus was discovered when a nasopharyngeal swab was collected and tested using the RT-PCR technique. Ferritin, LDH, WBC, and CRP were also tested using Min Vidus, AccEnT 200, Ruby system, and Latx in that sequence. The study revealed that COVID-19 patients had higher levels of ferritin, WBC, CRP, and LDH in their blood than healthy people, with values of 539,08 ng/mL, 44.7109/L, 22.95 mg/L, and 403.95 U/L for COVID-19 patients versus 77.103 ng/mL, 4.9.4109/L, 6.53 mg/L, and 171.56 U/L for healthy people. According to the existing data, males are more likely to be infected with COVID-19 (81%) than females (32%), and females had greater ferritin, CRP, WBC, and LDH levels than males. Because they are related to an optimum test for predicting COVID-19 infection, the recommended cut-off values for ferritin, WBC, CRP, and LDH are 109.8 ng/mL, 14.9109/L, 10.15 mg/L, and 229.33 U/L, respectively. Finally, an increase in ferritin levels in the inflammatory response to COVID-19 is linked to an increase in inflammatory markers including CRP, WBC, and LDH, which may assist in the diagnosis of COVID-19 infection.
Ferritin, which includes twenty-four light and heavy chains in varying proportions in different tissues, is primarily responsible for maintaining the body's iron metabolism. Its normal value is between 10 and 200 ngmL-1 in men and between 30-300 ngmL-1 in women. Iron is delivered to the tissue via them, and they act as immunomodulators, signaling molecules, and inflammatory markers. When ferritin level exceeds 1000 µgL-1, the patient is categorized as having hyperferritinemia. Iron chelators such as deferiprone, deferirox, and deferoxamine are currently FDA approved to treat iron overload. The inflammation cascade and poor prognosis of COVID-19 may be attributed to high ferritin levels. Critically ill patients can benefit from deferasirox, an iron chelator administered orally at 20-40 mgkg-1 once daily, as well as intravenous deferoxamine at 1000 mg initially followed by 500 mg every 4 to 12 hours. It can be combined with monoclonal antibodies, antioxidants, corticosteroids, and lactoferrin to make iron chelation therapy effective for COVID-19 victims. In this article, we analyze the antiviral and antifibrotic activity of iron chelators, thereby promoting iron depletion therapy as a potentially innovative treatment strategy for COVID-19.
During infections, the host redistributes iron in order to starve pathogens from this nutrient. Several proteins are involved in iron absorption, transport, and storage. Ferritin is the most important iron storage protein. It is composed of variable proportions of two peptides, the L- and H-ferritins (FTL and FTH). We previously showed that macrophages increase their expression of FTH1 when they are infected in vitro with Mycobacterium avium, without a significant increase in FTL. In this work, we investigated the role of macrophage FTH1 in M. avium infection in vivo. We found that mice deficient in FTH1 in myeloid cells are more resistant to M. avium infection, presenting lower bacterial loads and lower levels of proinflammatory cytokines than wild-type littermates, due to the lower levels of available iron in the tissues. Importantly, we also found that FTH1 produced by myeloid cells in response to infection may be found in circulation and that it plays a key role in iron redistribution. Specifically, in the absence of FTH1 in myeloid cells, increased expression of ferroportin is observed in liver granulomas and increased iron accumulation occurs in hepatocytes. These results highlight the importance of FTH1 expression in myeloid cells for iron redistribution during infection.
